{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["'''\n","Author: LIU X. xnd_liu@zju.edu.cn\n","\n","Date: 2023-01-12 10:07:16\n","\n","Description: For 2023 thesis use only.\n","'''\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"3b9b35f3e1ca444eb6b64c717f63c7a8","deepnote_cell_type":"markdown"},"source":["# Log"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 20230422\n","开始数值测试. 考虑对照文献设置信号长度和稀疏度, 以及噪声水平.\n","## 20230421\n","可以从ROC曲线下面积, F1-score(准确率和召回率的调和平均), 误差来衡量模型.\n","## 20230405\n","写完IRLSPKS. 算法性能比较可以从时间、先验贡献、RIP、重建误差、准确率和召回率、广义准确率和召回率(s-稀疏化后)等, 待补充.\n","## 20230404\n","把所有向量维数统一为`n`,之后可能的时间序列长度记为`N`.\n","## 20230402\n","大改代码. 把算法统一到各自的功能中,去掉多余的参数,例如先知信号等.将停机法则统一为相对更新率收敛至`eps=1e-6`.由于要比较迭代次数,可以设置可选输出`returnIter=True`.\n","题目含有'Exec!'的为直接可执行代码区域,注意绕开.\n","## 20230401\n","建议不要过度封装. 每个算法尽量展开写出.另外不要过度输出,可以只输出信号估计,而误差等可以不输出,而是改为在别的地方重新计算.|尝试加入haltingRule=('rIterErr',eps), 但不会以这种封装的方式, 而是针对个别算法.|以后要测试算法性能,考虑收敛时(因此要用'rIterErr'停机判定)取得的误差最小值,以及达到收敛需要的迭代次数.总的来看,'rIterErr'可能是比'rSampErr'更好的停机判据.\n","## 20230331\n","mod-(reg)-BPDN可以转化为一个二次规划问题, 用qp()解决.\n","`cvxopt.solvers.qp()`\n","(20230407) 可以进一步转化为线性规划, 用lp()解决."]},{"cell_type":"code","execution_count":32,"metadata":{"cell_id":"1c47ca66995545bf959e8ab5dc14c3f1","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":3,"execution_start":1680842284642,"source_hash":"d3bfa7a2"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from scipy import stats\n","import matplotlib.pyplot as plt\n","import cvxopt\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["import pickle\n","\n","# Variable saving.\n","\n","\n","def pickleSave(var, filename='.pickle'):\n","    if '.pickle' not in filename:\n","        filename = filename + '.pickle'\n","    with open(filename, 'wb') as f:\n","        pickle.dump(var, f)\n","    print('PickleSave Succeeded.')\n","    return\n","\n","# Variable loading.\n","\n","\n","def pickleLoad(filename):\n","    \"\"\"\n","    Make sure it's assigned to a variable.\n","    \"\"\"\n","    if '.pickle' not in filename:\n","        filename = filename + '.pickle'\n","    with open(filename, 'rb') as f:\n","        cache = pickle.load(f)\n","    print(\"PickleLoad Succeeded. Make sure it's assigned to a variable.\")\n","    return cache\n"]},{"cell_type":"markdown","metadata":{"cell_id":"fc6acc58a6fa424c953a52d0e3e0778b","deepnote_cell_type":"markdown"},"source":["# 1 预备函数\n","## 1.1 随机采样阵生成"]},{"cell_type":"code","execution_count":34,"metadata":{"cell_id":"27cb3073ea744dd89b069251235fff28","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4,"execution_start":1680842284641,"source_hash":"d73ce22c"},"outputs":[],"source":["# 随机采样阵生成\n","def randSampMat(m, n):\n","    \"\"\"\n","    Return m*n sampling matrix.\n","    Use type `np.float32`.\n","    \"\"\"\n","    # 用高斯分布抽样, 列单位化.\n","    A = np.random.randn(m, n).astype(np.float32)\n","    for j in range(A.shape[1]):\n","        A[:, j] = A[:, j] / np.sqrt(A[:, j].dot(A[:, j]))\n","    return A\n"]},{"cell_type":"markdown","metadata":{"cell_id":"0a91bad99a6a41c987a283e3614a06a3","deepnote_cell_type":"markdown"},"source":["## 1.2 共轭梯度法\n","(Iterative) Conjugate gradient method."]},{"cell_type":"code","execution_count":35,"metadata":{"cell_id":"fe69417ba17f4fb7ac2268af138529db","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":5,"execution_start":1680842284642,"source_hash":"bcf419df"},"outputs":[],"source":["def conjGrad(A, b, maxIter=-1, x=\"0\", eps=1e-6, showChangeRate=False):\n","    \"\"\"\n","    迭代的共轭梯度法. 要求A实正定对称.\n","    `x`:初始点.\n","    收敛相对误差|Δx[t]|/|x[t-1]|被`eps`控制.\n","    方法优点: 迭代至多进行k=len(b)次. A事先计算出,控制迭代次数,则复杂度O(k^2).\n","    不吝啬迭代则O(k^3).\n","    \"\"\"\n","    k = A.shape[0]  # 行/列数。\n","    if maxIter == -1:\n","        maxIter = k\n","    if x == '0':\n","        x = np.zeros(k)\n","    r = b - np.dot(A, x)\n","    p = r\n","    r2old = r.dot(r)\n","    for i in range(maxIter):\n","        Ap = A.dot(p)\n","        alpha = r2old / (p.dot(Ap))\n","        xOld = x\n","        x = x + alpha * p\n","        r = r - alpha * Ap\n","        r2new = r.dot(r)\n","        changeRate = np.sqrt((x-xOld).dot(x-xOld)/(eps**2 + x.dot(x)))\n","        # 相对迭代误差(改进率).\n","        if showChangeRate:\n","            print('Iter', i, ':', changeRate)\n","        if changeRate < eps:\n","            break\n","        p = r + (r2new/r2old)*p\n","        r2old = r2new\n","    return x\n"]},{"cell_type":"markdown","metadata":{"cell_id":"9313c0206f4248ddb55067b08c384876","deepnote_cell_type":"markdown"},"source":["## 1.3 限制等距常数估计"]},{"cell_type":"code","execution_count":36,"metadata":{"cell_id":"fe9f28032e374ea1afa51e947532dc6b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1680842284654,"source_hash":"7f460242"},"outputs":[],"source":["# RIP测试.\n","class RIPTest:\n","    def __init__(self, A, s):\n","        \"\"\"\n","        Return possible delta_s given matrix `A` and sparsity `s`.\n","\n","        Contain 2 methods:\n","            `RIPTest(A,s).monteCarlo(nVec,show)`: Monte Carlo method;\n","            `RIPTest(A,s).singularValue()`: singularValue method.\n","        \"\"\"\n","        self.A = A\n","        self.s = s\n","\n","    # Monte-Carlo method.\n","\n","    def monteCarlo(self, nVec=1e5, show=True):  # 这是一个对象方法.\n","        \"\"\"\n","        Return possible delta_s given matrix `A` and sparsity `s`. \\n\n","        `nVec`: Number of vectors to test. \\n\n","        `show`: Whether to draw the distribution of amplifications. \\n\n","        Running time: \\n\n","            O(nVec=10000,n=10000,m=400)~70sec; \\n\n","            O(nVec=5000,n=5000,m=200)~10sec; \\n\n","            O(nVec=100000,n=200,m=50)~3sec.\n","        \"\"\"\n","        n = self.A.shape[1]\n","        nVec = int(nVec)  # 转化形如`1e5`的输入.\n","        V = np.zeros((n, nVec), order='F', dtype=np.float32)  # 由多个s-稀疏的列向量组成.\n","        Supps = np.array(\n","            [np.random.choice(range(n), self.s, replace=False) for i in range(nVec)])\n","        # 随机抽取支集, 存为每一行.\n","        Entries = np.array(\n","            [np.random.randn(self.s).astype(np.float32) for i in range(nVec)])\n","        # 随机赋予支集项的值, 存为每一行. 未正规化.\n","        for j in range(nVec):\n","            # supp = Supps[j]\n","            # entries = Entries[j]\n","            V[Supps[j], j] = Entries[j]/np.linalg.norm(Entries[j])\n","        V = np.dot(self.A, V)\n","        # 象.\n","        Amplifications = np.array(\n","            list(map(lambda v: np.linalg.norm(v), np.transpose(V))))\n","        ampMax = np.max(Amplifications)\n","        delta1 = ampMax-1\n","        ampMin = np.min(Amplifications)\n","        delta2 = 1-ampMin\n","        delta = max(delta1, delta2)\n","\n","        if show == True:\n","            # 用Gaussian近似检测delta估计是否超出3-sigma,若是,则认为delta即使再估计也不会显著增加,基本准确.\n","            var = np.var(Amplifications)\n","            mean = np.mean(Amplifications)\n","            threeSigma = 3*np.sqrt(var)\n","            ThreeSigmaPoints = [mean - threeSigma, mean + threeSigma]\n","            Xnorm = np.linspace(ThreeSigmaPoints[0], ThreeSigmaPoints[1], 100)\n","            Ynorm = stats.norm.pdf((Xnorm-mean)/np.sqrt(var))/np.sqrt(var)\n","\n","            plt.hist(Amplifications, bins=100,\n","                     density=True, label='Amplifications')\n","            plt.plot(Xnorm, Ynorm, 'r:', label='Gaussian Reference')\n","            plt.axvline(\n","                ThreeSigmaPoints[0], linestyle='-.', color='g', label='-3 sigma')\n","            plt.axvline(\n","                ThreeSigmaPoints[1], linestyle='--', color='m', label='+3 sigma')\n","            plt.xlabel('Amp.')\n","            plt.ylabel('Density')\n","            plt.legend()\n","            plt.show()\n","            print(\"3-sigma points: [1 - {:}, 1 + {:}]\".format(1 -\n","                  ThreeSigmaPoints[0], ThreeSigmaPoints[1]-1))\n","\n","            if delta == delta1:\n","                side = 'Right'\n","            else:\n","                side = 'Left'\n","            print(\"Side:\", side)\n","        return delta\n","\n","    # SingularValue method.\n","\n","    def singularValue(self, SAFECODE, showSingularValues=True, mode='memory-saving'):\n","        \"\"\"\n","        有内存泄漏危险, 勿用! \\n\n","        确认使用时输入参数`SAFECODE=CONFIRM`. \\n\n","        Return delta_s. \\n\n","        `showSingularValues`: Whether to show the two max&min singularValues of all submatrices. \\n\n","        Running time: \\n\n","            `mode='memory-saving'`: O(n=200,m=20,s=3)~30sec; O(n=2000,m=20,s=2)~39sec; O(n=2000,m=20,s=3)~ >5min. \\n\n","            `mode='fast'`: O(n=200,m=20,s=3)~23sec; O(n=2000,m=20,s=2)~27sec; O(n=2000,m=20,s=3)~ >2min(MemoryError). \\n        \n","        建议: \\n\n","            1, 采用分布式计算, 因为耗时关于s指数级增长; \\n\n","            2, 改用Monte-Carlo方法, 其估计概率已足够大; \\n\n","            3, `fast`模式对于稍大矩阵几乎不能用, 基本上会报错`MemoryError`.\n","        \"\"\"\n","        if SAFECODE != 'CONFIRM':\n","            print('Not safe!')\n","            return\n","\n","        from itertools import combinations as cb\n","\n","        n = self.A.shape[1]\n","        # 以时间换空间: 使用s个指针Pointers, 列举指针组合.\n","        if mode == 'memory-saving':\n","            PtrCombinations = cb(range(n), self.s)\n","            maxSv, minSv = 1, 1\n","            for ptr in PtrCombinations:\n","                ptr = list(ptr)\n","                Svs = np.sqrt(np.linalg.eigvals(\n","                    self.A[:, ptr].T.dot(self.A[:, ptr])))\n","                # `Svs` for 'Singular Values'.\n","                # Only accept float32+ type.\n","                maxSv = max(np.max(Svs), maxSv)\n","                minSv = min(np.min(Svs), minSv)\n","        # 以空间换时间.\n","        elif mode == 'fast':\n","            Submatrices = np.array(list(cb(self.A.transpose(), self.s)))\n","            Svs = np.sqrt(np.linalg.eigvals(Submatrices.T.dot(Submatrices)))\n","\n","            maxSv = max(Svs)\n","            minSv = min(Svs)\n","\n","        delta = max(maxSv - 1, 1 - minSv)\n","        if showSingularValues == True:\n","            print('Max singular value:', maxSv)\n","            print('Min singular value:', minSv)\n","        return delta\n","\n","    # A mixed version.\n","\n","    def mixedMethod(self, times=10000, showSingularValues=True):\n","        \"\"\"\n","        A better and safe mixed version of Monte-Carlo & SingularValue.\n","        \"\"\"\n","        n = self.A.shape[1]\n","        maxSv, minSv = 1, 1\n","        for t in range(times):\n","            comb = np.random.choice(range(n), self.s, replace=False)\n","            submatrix = self.A[:, comb].astype(np.float32)\n","            Svs = np.linalg.eigvals(np.dot(submatrix.transpose(), submatrix))\n","            # `Svs` for 'Singular Values'.\n","            # Only accept float32+ type.\n","            maxSv = max(np.sqrt(np.max(Svs)), maxSv)\n","            minSv = min(np.sqrt(np.min(Svs)), minSv)\n","\n","        delta = max(maxSv - 1, 1 - minSv)\n","        if showSingularValues == True:\n","            print('Max singular value:', maxSv)\n","            print('Min singular value:', minSv)\n","        return delta\n"]},{"cell_type":"markdown","metadata":{"cell_id":"c7811bf50b5e42798291fa8f66d967be","deepnote_cell_type":"markdown"},"source":["## 1.4 硬阈值函数"]},{"cell_type":"code","execution_count":37,"metadata":{"cell_id":"622bd9e2b33a4adbbe312626dbb84b31","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1,"execution_start":1680842284670,"source_hash":"29b32a7a"},"outputs":[],"source":["# 硬阈值函数\n","def hardThreshold(x, s, T0=[]):\n","    \"\"\"\n","    Return x with its largest s-k entries and k entries indexed in T0, the rest set to 0.\n","    \"\"\"\n","    n = len(x)\n","    k = len(T0)\n","    comparingVec = x.copy()\n","    comparingVec[T0] = 0  # 去掉支集项以寻找剩余元素的s-k个最大值.\n","    delta = np.abs(comparingVec).argsort()[:-(s-k+1):-1]  # 返回s-k个绝对最大值的索引.\n","    supp = np.append(T0, delta).astype('int64')\n","    new = np.zeros(n)\n","    new[supp] = x[supp]\n","\n","    return new\n"]},{"cell_type":"markdown","metadata":{"cell_id":"ba5a22fcb59640c38bcb835aa0d83063","deepnote_cell_type":"markdown"},"source":["## 1.5 取支集"]},{"cell_type":"code","execution_count":38,"metadata":{"cell_id":"2d3f1305a7d6423ca331c33249dea790","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1,"execution_start":1680842284670,"source_hash":"5d98cbe3"},"outputs":[],"source":["def getSupp(x: np.ndarray, s: int = -1):\n","    \"\"\"\n","    Return supp(x_s) corresponding to from Largest to Smallest. \\n\n","    If `s` left default, -1, then s=sum(x!=0).\n","    \"\"\"\n","    if s == -1:\n","        s = sum(1 - np.isclose(x, 0))\n","    return np.abs(x).argsort()[:-s-1:-1]\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 1.6 测试信号生成"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# Rademacher(1,-1,Prob=0.5) on support.\n","def randSparseSignal(n=2000, s=50, size=10000, returnSupports=False, allowLowerSparsity=False):\n","    \"\"\"\n","    Generate `size` number of signals of dimension `n` and sparsity `s`.\n","    Aranged by columns.\n","\n","    If `returnSupports`=`True` then also return Supports of Signals aranged by columns,\n","    repetitions might be included.\n","    \"\"\"\n","    size = int(size)  # 转化形如`1e5`的输入.\n","    V = np.zeros((n, size), order='F', dtype=np.float32)\n","    Supps = np.array([np.random.choice(\n","        range(n), s, replace=allowLowerSparsity) for _ in range(size)])\n","    # 随机抽取支集, 存为每一行.\n","    Entries = np.array(\n","        [np.random.binomial(1, 0.5, s).astype(np.float32)*2-1 for _ in range(size)])\n","    # 随机赋予支集项的值, 存为每一行.\n","    for j in range(size):\n","        V[Supps[j], j] = Entries[j]\n","    if returnSupports == True:\n","        return dict(\n","            Signals=V,\n","            Supports=Supps.T\n","        )\n","    else:\n","        return V\n"]},{"cell_type":"markdown","metadata":{"cell_id":"d4f4f0eb09ba40a8be5dc2902263ddac","deepnote_cell_type":"markdown"},"source":["## (Deprecated). errAnalyze()\n","可以作以后误差分析的参考."]},{"cell_type":"code","execution_count":40,"metadata":{"cell_id":"377741bc7232438ab4eb701bc7072379","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":18,"execution_start":1680842284671,"source_hash":"b7cc97c3"},"outputs":[],"source":["# def errAnalyze(xReal,suppReal,x1,n,s,showPrecisionAndRecall,iterCount,eps,y,err,yNorm):\n","#     \"\"\"\n","#     errAnalyze(xReal,suppReal,x1,n,s,showPrecisionAndRecall,iterCount,eps,y,err,yNorm)\n","#         -> dict(\n","#             estimate,iterCount,eps,y,errY,relativeErrY,confusion\n","#         )\n","#     \"\"\"\n","#     if not (xReal is None):\n","#         if suppReal is None:\n","#             suppReal = np.argsort(np.abs(xReal))[:-(s+1):-1] #兼容compressible signal.\n","\n","#         # Compute confusion matrix.\n","#         nPositive = np.sum(1-np.isclose(x1,0))\n","#         nTruePositive = np.sum(1-np.isclose(x1[suppReal],0))\n","#         nFalsePositive = nPositive - nTruePositive\n","#         nNegative = n - nPositive\n","#         nFalseNegative = np.sum(np.isclose(x1[suppReal],0))\n","#         nTrueNegative = nNegative - nFalseNegative\n","\n","#         confusion = pd.DataFrame(np.array([\n","#             [nTruePositive,nTrueNegative],\n","#             [nFalsePositive,nFalseNegative]\n","#         ]), columns=['positive','negative'],index=['true','false'])\n","#         if showPrecisionAndRecall == True:\n","#             print('precision:',nTruePositive/(nTruePositive + nFalsePositive))\n","#             print('recall:',nTruePositive/(nTruePositive + nFalseNegative))\n","\n","#     else:\n","#         confusion = None\n","\n","#     return dict(\n","#         estimate=x1,\n","#         iterCount=iterCount,\n","#         eps=eps,\n","#         y=y,\n","#         errY=err,\n","#         relativeErrY=err/yNorm,\n","#         confusion=confusion\n","#     )\n"]},{"cell_type":"markdown","metadata":{"cell_id":"6df26145cc1940c09d6a818cce435c33","deepnote_cell_type":"markdown"},"source":["# 2 静态CS算法\n","## 2.1 IHT-PKS"]},{"cell_type":"code","execution_count":41,"metadata":{"cell_id":"76bdeb6f09d74a6ca3a772beaac88533","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1,"execution_start":1680842284688,"source_hash":"52695bd6"},"outputs":[],"source":["# IHT-PKS\n","def IHTPKS(y: np.ndarray, Phi: np.ndarray, s: int, x0='0', T0=[], mu=1,\n","           maxIter: int = 100, eps=1e-6,\n","           returnIter=False,\n","           showIfMaxIter=False, showChangeRate=False):\n","    \"\"\"\n","    `mu`:Learning rate. \\n\n","    Return signal estimate. \\n\n","    If `returnIter`, return tuple(signalEsti,iter).\n","    \"\"\"\n","    n = Phi.shape[1]  # signal length.\n","    if x0 == '0':\n","        x0 = np.zeros(n)\n","\n","    for t in range(maxIter):\n","        p = x0 + mu * Phi.T.dot(y - Phi.dot(x0))  # proxy.\n","        x1 = hardThreshold(p, s, T0)\n","        dx = x1-x0\n","        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2))\n","        if showChangeRate:\n","            print('Iter:', t, 'ChangeRate:', changeRate)  # Log.\n","        if changeRate < eps:\n","            iter = t\n","            break\n","        else:\n","            x0 = x1\n","    else:  # Reach maxIter.\n","        iter = maxIter-1\n","        if showIfMaxIter:\n","            print('Reach maxIter:', maxIter)\n","\n","    if returnIter:\n","        return (x1, iter)\n","    else:\n","        return x1\n"]},{"cell_type":"markdown","metadata":{"cell_id":"07b2426e9f304490a5ea9cbb83c57d41","deepnote_cell_type":"markdown"},"source":["## 2.2 OMP-PKS"]},{"cell_type":"code","execution_count":42,"metadata":{"cell_id":"dd488dace18a49ab842ce7cbb8a378e2","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1680842284688,"source_hash":"e324a159"},"outputs":[],"source":["def OMPPKS(y, Phi: np.ndarray, x0='0', T0=[],\n","           maxIter: int = 100, eps=1e-6,\n","           returnIter=False,\n","           showIfMaxIter=False, showChangeRate=False):\n","    \"\"\"\n","    Does not require sparsity 's'.\n","    \"\"\"\n","    # Init.\n","    n = Phi.shape[1]\n","    if x0 == '0':\n","        x0 = np.zeros(n)\n","    supp = list(T0)  # PKS.\n","\n","    # Iteration.\n","    for t in range(maxIter):\n","        p = Phi.T.dot(y - Phi.dot(x0))  # proxy.\n","        j = np.argmax(np.abs(p))\n","        if j not in supp:\n","            supp.append(j)\n","        x1 = np.zeros(n)\n","        # Use conjGrad to solve lstsq problem.\n","        # Note here the problem is |Phi.T.dot(Phi).dot(x)-Phi.T.dot(y)|->0.\n","        x1[supp] = conjGrad(Phi[:, supp].T.dot(\n","            Phi[:, supp]), Phi[:, supp].T.dot(y))\n","\n","        dx = x1 - x0\n","        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2))\n","        if showChangeRate:\n","            print('Iter:', t, 'ChangeRate:', changeRate)  # Log.\n","        if changeRate < eps:\n","            iter = t\n","            break\n","        else:\n","            x0 = x1\n","    else:  # maxIter.\n","        iter = maxIter-1\n","        if showIfMaxIter:\n","            print('Reach maxIter:', maxIter)\n","\n","    if returnIter:\n","        return (x1, iter)\n","    else:\n","        return x1\n"]},{"cell_type":"markdown","metadata":{"cell_id":"a3e9463415da45afb8e4bb5cce596752","deepnote_cell_type":"markdown"},"source":["## 2.3 CoSaMP-PKS"]},{"cell_type":"code","execution_count":43,"metadata":{"cell_id":"d52f5bd9dc4540699cffd8dad0c926d5","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1,"execution_start":1680842284705,"source_hash":"fce40208"},"outputs":[],"source":["# CosampPKS\n","def CosampPKS(y: np.ndarray, Phi: np.ndarray, s: int, T0=[],\n","              conjGradIter=-1,\n","              maxIter: int = 100, eps=1e-6,\n","              returnIter=False,\n","              showIfMaxIter=False, showChangeRate=False):\n","    \"\"\"\n","    Return signal estimate. \\n\n","    If `returnIter`, return tuple(signalEsti,iter).\n","\n","    If `conjGradIter` left default, -1, then it iterates enough times.\n","    \"\"\"\n","    n = Phi.shape[1]  # signal length.\n","    T0 = list(T0)\n","    x0 = np.zeros(n)\n","    if len(T0) > 0:  # A priori.\n","        x0[T0] = conjGrad(Phi[:, T0].T.dot(Phi[:, T0]),\n","                          Phi[:, T0].T.dot(y), conjGradIter)\n","    r = y - Phi[:, T0].dot(x0[T0])  # 感知残差.\n","    K = s - len(T0)  # 剩余稀疏度.\n","\n","    for t in range(maxIter):\n","        p = Phi.T.dot(r)  # proxy.\n","        Omega = getSupp(p, 2*K)  # 2K-supp of proxy.\n","        Tm = list(set(Omega) | set(getSupp(x0)))  # Supp merge.\n","        b = np.zeros(n)\n","        b[Tm] = conjGrad(Phi[:, Tm].T.dot(Phi[:, Tm]),\n","                         Phi[:, Tm].T.dot(y), conjGradIter)\n","        # Elaborative solution.\n","        A = b.copy()\n","        A[T0] = 0  # Auxiliary.\n","        x1 = np.zeros(n)\n","        supp = list(set(T0) | set(getSupp(A, K)))\n","        x1[supp] = b[supp]\n","        r = y - Phi.dot(x1)\n","\n","        dx = x1 - x0\n","        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2))\n","        if showChangeRate:\n","            print('Iter:', t, 'ChangeRate:', changeRate)  # Log.\n","        if changeRate < eps:\n","            iter = t\n","            break\n","        else:\n","            x0 = x1\n","    else:  # Reach maxIter.\n","        iter = maxIter-1\n","        if showIfMaxIter:\n","            print('Reach maxIter:', maxIter)\n","\n","    if returnIter:\n","        return (x1, iter)\n","    else:\n","        return x1\n"]},{"cell_type":"markdown","metadata":{"cell_id":"f35166249bc44fdab189db0babb4c78e","deepnote_cell_type":"markdown"},"source":["## 2.4 RWLS-Sl0-PKS"]},{"cell_type":"code","execution_count":44,"metadata":{"cell_id":"5c82f22a61bf4a8199ddcf86336dd166","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1680842284705,"source_hash":"43abda79"},"outputs":[],"source":["# RWLSSl0PKS.\n","def RWLSSl0PKS(y: np.ndarray, Phi: np.ndarray, T0=[],\n","               lamb=1e-4, sigmaMin=1e-8,\n","               conjGradIter=-1,\n","               maxIter: int = 100, eps=1e-6,\n","               returnIter=False,\n","               showIfMaxIter=False, showChangeRate=False):\n","    \"\"\"\n","    `lamb`: Recommend (noise^2)*sqrt(1.5*log(n)). \\n\n","    Return signal estimate. \\n\n","    If `returnIter`, return tuple:(signalEsti,iter). \\n\n","    If `conjGradIter` left default, -1, then it iterates enough times.\n","    \"\"\"\n","    m, n = Phi.shape\n","    T0 = list(T0)\n","    x0 = np.zeros(n)\n","    K = int(m/np.log(n/m))  # Very rough Sparsity estimate.\n","    # Init.\n","    w = np.ones(n)  # We let w=inverse(w1,...,wn)\n","    w[T0] = 100\n","    # Weight by row.\n","    x0 = (w * Phi).T.dot(conjGrad(Phi.dot((w * Phi).T)+lamb*np.identity(m), y))\n","    # Cost:O((m^2*n^2)^3)=poly(m,n).\n","\n","    for t in range(maxIter):\n","        sigma = max(sigmaMin, sorted(np.abs(x0))[-(K+1)])\n","        w = (sigma + np.abs(x0))**2\n","        w[T0] *= 100\n","        x1 = (w * Phi).T.dot(conjGrad(Phi.dot((w * Phi).T)+lamb*np.identity(m), y))\n","\n","        dx = x1 - x0\n","        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2))\n","        if showChangeRate:\n","            print('Iter:', t, 'ChangeRate:', changeRate)  # Log.\n","        if changeRate < eps:\n","            iter = t\n","            break\n","        x0 = x1\n","    else:  # Reach maxIter.\n","        iter = maxIter-1\n","        if showIfMaxIter:\n","            print('Reach maxIter:', maxIter)\n","\n","    if returnIter:\n","        return (x1, iter)\n","    else:\n","        return x1\n"]},{"cell_type":"markdown","metadata":{"cell_id":"f6fd683f47dd44e0b424fd4ecf98016a","deepnote_cell_type":"markdown"},"source":["## 2.5 IRLS-PKS"]},{"cell_type":"code","execution_count":45,"metadata":{"cell_id":"68b4d3d6b50e41898b38ee49873e726e","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1680842284745,"source_hash":"4a01e22d"},"outputs":[],"source":["# IRLSPKS.\n","def IRLSPKS(y: np.ndarray, Phi: np.ndarray, T0=[],\n","            p: int = 1, mu=1e-3, tau=1e-3,\n","            conjGradIter=-1,\n","            maxIter: int = 100, eps=1e-6,\n","            returnIter=False,\n","            showIfMaxIter=False, showChangeRate=False):\n","    \"\"\"\n","    `p`: Norm number, in (0,1]. \\n\n","    `mu`: Normalizing param. `sqrt(mu)/100`'s Minimum is `eps`. \\n\n","    `tau`: Short for tau^(2-p) in the paper. Weighting param. \\n\n","    Return signal estimate. \\n\n","    If `returnIter`, return tuple:(signalEsti,iter). \\n\n","    If `conjGradIter` left default, -1, then it iterates enough times.\n","    \"\"\"\n","    n = Phi.shape[1]  # signal length.\n","    T0 = list(T0)\n","    x0 = np.zeros(n)\n","    # Init.\n","    q = np.ones(n)  # q=(q1,...,qn)\n","    q[T0] = tau\n","    # Q = np.diag(q)\n","    # Inverse weight matrix. Not used so as to accelerate.\n","    x0 = (q * Phi).T.dot(conjGrad(Phi.dot((q * Phi).T), y))  # Weight by row.\n","    # Cost:O((m^2*n^2)^3)=poly(m,N).\n","\n","    for t in range(maxIter):\n","        q = np.abs(x0)**(2-p)\n","        q[T0] *= tau\n","        q += mu\n","        x1 = (q * Phi).T.dot(conjGrad(Phi.dot((q*Phi).T), y))\n","        dx = x1 - x0\n","        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2))\n","        if showChangeRate:\n","            print('Iter:', t, 'ChangeRate:', changeRate)  # Log.\n","        if changeRate < np.sqrt(mu)/100:\n","            if mu <= eps:\n","                iter = t\n","                break\n","            else:\n","                mu /= 10\n","        x0 = x1\n","    else:  # Reach maxIter.\n","        iter = maxIter-1\n","        if showIfMaxIter:\n","            print('Reach maxIter:', maxIter)\n","\n","    if returnIter:\n","        return (x1, iter)\n","    else:\n","        return x1\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2.6 Modified-CS"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["# ModCS\n","def ModCS(y: np.ndarray, Phi: np.ndarray, T0=[],\n","          lamb=1e-1):\n","    \"\"\"\n","    Return xEsti. \\n\n","    `lamb`: s.t. Dantzig |Phi'@(y-Phi@x)| < `lamb`.\n","    \"\"\"\n","    n = Phi.shape[1]\n","    T0 = list(T0)\n","    x = np.zeros(n)\n","\n","    # Variables for LP:\n","    c = np.ones(2*n)\n","    c[T0] = 0\n","    c[n:][T0] = 0\n","    c = cvxopt.matrix(c, (2*n, 1), 'd')\n","    F = np.block([[Phi.T.dot(Phi), -Phi.T.dot(Phi)]])\n","    d = Phi.T.dot(y)\n","    G = np.block([[-np.identity(2*n)],\n","                  [F],\n","                  [-F]])\n","    G = cvxopt.matrix(G, (4*n, 2*n), 'd')\n","    h = np.block([np.zeros(2*n),\n","                  d + lamb*np.ones(n),\n","                  -d + lamb*np.ones(n)])\n","    h = cvxopt.matrix(h, (4*n, 1), 'd')\n","    xsol = cvxopt.solvers.lp(c, G, h)\n","    xsol = np.array(xsol['x'])\n","    xsol = xsol[:n]-xsol[n:]  # Note! This solution is 2-d.\n","    xsol = xsol[:, 0]\n","    x = xsol\n","\n","    return x\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2.7 Weighted-l1"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["# wl1\n","def weightedl1(y: np.ndarray, Phi: np.ndarray, T0=[],\n","               w=1e-2, lamb=1e-1):\n","    \"\"\"\n","    Return xEsti. \\n\n","    `lamb`: s.t. Dantzig |Phi'@(y-Phi@x)| < `lamb`. \\n\n","    `w`: Weight for x[T0].\n","    \"\"\"\n","    n = Phi.shape[1]\n","    T0 = list(T0)\n","    x = np.zeros(n)\n","\n","    # Variables for LP:\n","    c = np.ones(2*n)\n","    c[T0] = 1e-2\n","    c[n:][T0] = 1e-2\n","    c = cvxopt.matrix(c, (2*n, 1), 'd')\n","    F = np.block([[Phi.T.dot(Phi), -Phi.T.dot(Phi)]])\n","    d = Phi.T.dot(y)\n","    G = np.block([[-np.identity(2*n)],\n","                  [F],\n","                  [-F]])\n","    G = cvxopt.matrix(G, (4*n, 2*n), 'd')\n","    h = np.block([np.zeros(2*n),\n","                  d + lamb*np.ones(n),\n","                  -d + lamb*np.ones(n)])\n","    h = cvxopt.matrix(h, (4*n, 1), 'd')\n","    xsol = cvxopt.solvers.lp(c, G, h)\n","    xsol = np.array(xsol['x'])\n","    xsol = xsol[:n]-xsol[n:]  # Note! This solution is 2-d.\n","    xsol = xsol[:, 0]\n","    x = xsol\n","\n","    return x\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2.8 Reweighted-l1"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["# rwl1\n","def reweightedl1(y: np.ndarray, Phi: np.ndarray, T0=[],\n","                 mu=1e-3, lamb=1e-1,\n","                 maxIter: int = 100, eps=1e-6,\n","                 returnIter=False,\n","                 showIfMaxIter=False, showChangeRate=False):\n","    \"\"\"\n","    `lamb`: Dantzig boundary. \\n\n","    `mu`: Regularizing param of weights. \\n\n","    Return signal estimate. \\n\n","    If `returnIter`, return tuple:(signalEsti,iter). \\n\n","    \"\"\"\n","    m, n = Phi.shape\n","    T0 = list(T0)\n","    x0 = np.zeros(n)\n","    # Init.\n","    w = np.ones(n)\n","\n","    for t in range(maxIter):\n","        w = (np.abs(x0) + mu)**(-1)\n","        w[T0] *= 0.1\n","\n","        # Variables for LP:\n","        c = np.append(w, w)\n","        c = cvxopt.matrix(c, (2*n, 1), 'd')\n","        F = np.block([[Phi.T.dot(Phi), -Phi.T.dot(Phi)]])\n","        d = Phi.T.dot(y)\n","        G = np.block([[-np.identity(2*n)],\n","                      [F],\n","                      [-F]])\n","        G = cvxopt.matrix(G, (4*n, 2*n), 'd')\n","        h = np.block([np.zeros(2*n),\n","                      d + lamb*np.ones(n),\n","                      -d + lamb*np.ones(n)])\n","        h = cvxopt.matrix(h, (4*n, 1), 'd')\n","        xsol = cvxopt.solvers.lp(c, G, h)\n","        xsol = np.array(xsol['x'])\n","        xsol = xsol[:n]-xsol[n:]  # Note! This solution is 2-d.\n","        xsol = xsol[:, 0]\n","        x1 = xsol\n","\n","        dx = x1 - x0\n","        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2))\n","        if showChangeRate:\n","            print('Iter:', t, 'ChangeRate:', changeRate)  # Log.\n","        if changeRate < eps:\n","            iter = t\n","            break\n","        x0 = x1\n","    else:  # Reach maxIter.\n","        iter = maxIter-1\n","        if showIfMaxIter:\n","            print('Reach maxIter:', maxIter)\n","\n","    if returnIter:\n","        return (x1, iter)\n","    else:\n","        return x1\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2.9 Reg-mod-BPDN"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["# regModBPDN\n","def regModBPDN(y: np.ndarray, Phi: np.ndarray, T0=[],\n","               x0=None, gamma=1., lamb=1.):\n","    \"\"\"\n","    Return xEsti. \\n\n","    Params: \\n\n","        min `gamma`*|x[T0^c]|(l1) + \\n\n","            0.5|y-Phi@x|(l2)^2 + \\n\n","            0.5*`lamb`*|x[T0]-`x0`[T0]|(l2)^2.\n","    \"\"\"\n","    n = Phi.shape[1]\n","    T0 = list(T0)\n","    x = np.zeros(n)\n","    if x0 is None:  # Degenerate to mod-MPDN.\n","        x0 = np.zeros(n)\n","        lamb = 1e-12\n","\n","    # Variables for Quadratic Program:\n","    posNeg = np.block([[np.identity(n), -np.identity(n)]])\n","    oneT0 = np.zeros(n)\n","    oneT0[T0] = 1\n","    diagT0 = np.diag(oneT0)\n","    P = posNeg.T @ (lamb * diagT0 + Phi.T @ Phi) @ posNeg\n","    P = cvxopt.matrix(P, (2*n, 2*n), 'd')\n","    oneT0c = np.ones(n)\n","    oneT0c[T0] = 0\n","    oneOneT0c = np.append(oneT0c, oneT0c)\n","    q = gamma * oneOneT0c - posNeg.T @ Phi.T @ y - lamb * posNeg.T @ diagT0 @ x0\n","    q = cvxopt.matrix(q, (2*n, 1), 'd')\n","    G = -np.identity(2*n)\n","    G = cvxopt.matrix(G, (2*n, 2*n), 'd')\n","    h = np.zeros(2*n)\n","    h = cvxopt.matrix(h, (2*n, 1), 'd')\n","\n","    xsol = cvxopt.solvers.qp(P, q, G, h)\n","    xsol = np.array(xsol['x'])\n","    xsol = xsol[:n]-xsol[n:]  # Note! This solution is 2-d.\n","    xsol = xsol[:, 0]\n","    x = xsol\n","\n","    return x\n"]},{"cell_type":"markdown","metadata":{"cell_id":"0a47ed4d5d504756a6fe2ed2f05817f2","deepnote_cell_type":"markdown"},"source":["# 3 动态CS算法\n","## 3.1 LS-CS-residual"]},{"cell_type":"markdown","metadata":{"cell_id":"d3b887392381445bb26d744f4011aa7e","deepnote_cell_type":"markdown"},"source":["### 3.1.1 静态核 LS-CS-residual"]},{"cell_type":"code","execution_count":50,"metadata":{"cell_id":"2abebe989ddc441185799dae88c33a07","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1680842284746,"source_hash":"bd9d2709"},"outputs":[],"source":["# LSCSresidualStatic\n","def LSCSResidualStatic(y: np.ndarray, Phi: np.ndarray, T0=[],\n","                       lamb=1e-1, alpha=0.05, alphaDel=0.15,\n","                       conjGradIter=-1):\n","    \"\"\"\n","    Return (xEsti, T_Esti).\n","    \"\"\"\n","    m, n = Phi.shape\n","    T0 = list(T0)\n","    x0 = np.zeros(n)  # x_init\n","    x0[T0] = conjGrad(Phi[:, T0].T.dot(Phi[:, T0]), Phi[:, T0].T.dot(y))\n","    yRes = y - Phi.dot(x0)  # LS-residual y_res\n","    # Variables for LP:\n","    c = cvxopt.matrix(np.ones(2*n), (2*n, 1), 'd')\n","    F = np.block([[Phi.T.dot(Phi), -Phi.T.dot(Phi)]])\n","    dRes = Phi.T.dot(yRes)\n","    G = np.block([[-np.identity(2*n)],\n","                  [F],\n","                  [-F]])\n","    G = cvxopt.matrix(G, (4*n, 2*n), 'd')\n","    h = np.block([np.zeros(2*n),\n","                  dRes + lamb*np.ones(n),\n","                  -dRes + lamb*np.ones(n)])\n","    h = cvxopt.matrix(h, (4*n, 1), 'd')\n","    xsol = cvxopt.solvers.lp(c, G, h)\n","    xsol = np.array(xsol['x'])\n","    xsol = xsol[:n]-xsol[n:]  # Note! This solution is 2-d.\n","    xsol = xsol[:, 0]\n","    x0 += xsol  # x_CSres\n","    # Detect:\n","    Tdet = list(set(T0) | set(np.arange(n)[np.abs(x0) > alpha]))\n","    x0 = np.zeros(n)\n","    x0[Tdet] = conjGrad(Phi[:, Tdet].T.dot(\n","        Phi[:, Tdet]), Phi[:, Tdet].T.dot(y))\n","    # x_det\n","    # Delete:\n","    Tt = list(set(Tdet) - set(np.arange(n)[np.abs(x0) <= alphaDel]))\n","    x0 = np.zeros(n)  # x_final\n","    x0[Tt] = conjGrad(Phi[:, Tt].T.dot(Phi[:, Tt]), Phi[:, Tt].T.dot(y))\n","\n","    return (x0, Tt)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 3.1.2 动态 LS-CS\n","我们采取这样的策略: 对于第一个信号我们假设有足够的采样使得可以得到先知的信息. 因此下面的`Y[:,0]`是事实上的第二个信号采样. `x0`,`T0`为第一个信号的先知信息."]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["# LSCSresidual\n","def LSCSResidual(Y: np.ndarray, Phi: np.ndarray, x0: np.ndarray, T0=[],\n","                 lamb=1e-1, alpha=0.05, alphaDel=0.15,\n","                 conjGradIter=-1,\n","                 ):\n","    \"\"\"\n","    Return signal sequence reconstruction for observed `Y`.\n","    \"\"\"\n","    if T0 == []:\n","        T0 = list(getSupp(x0))\n","    m, N = Y.shape  # Sequence length.\n","    assert m == Phi.shape[0]\n","    n = Phi.shape[1]\n","    X = np.zeros((n, N))\n","    for t in range(N):\n","        X[:, t], T0 = LSCSResidualStatic(\n","            Y[:, t], Phi, T0, lamb, alpha, alphaDel, conjGradIter)\n","    print('LSCSresidual Succeeded.')\n","    return X\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 3.2 KF-CS-residual\n","### 3.2.1 静态核 KF-CS"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["# KFCSresidualStatic\n","def KFCSResidualStatic(y: np.ndarray, Phi: np.ndarray, x0=None, T0=[],\n","                       P0=None, sigma2Sys=0.01, sigma2=0.01, lamb=0.1,\n","                       alpha=0.05, alphaDel=0.15,\n","                       ):\n","    \"\"\"\n","    Return (xEsti, P_Esti, T_Esti).\n","    \"\"\"\n","    m, n = Phi.shape\n","    if x0 is None:\n","        x0 = np.zeros(n)\n","    if P0 is None:\n","        P0 = np.zeros((n, n))\n","    T0 = list(T0)\n","    Q = np.zeros((n, n))\n","    np.diag(Q)[T0] = sigma2Sys\n","    P10 = P0 + Q\n","    # P10[T0,T0] is non-zero\n","    K = np.zeros((n, m))\n","    K[T0, :] = P10[T0, T0] @ Phi[:, T0].T @ np.linalg.inv(\n","        Phi[:, T0] @ P10[T0, T0] @ Phi[:, T0].T + sigma2 * np.identity(m))\n","    # O(m^3)\n","    # K[T0,:] is non-zero.\n","    # P[T0,T0] is nonzero.\n","    P = np.zeros((n, n))\n","    P[T0, T0] = (np.identity(len(T0)) - K[T0, :] @ Phi[:, T0]) @ P10[T0, T0]\n","    x = np.zeros(n)\n","    x[T0] = (np.identity(len(T0)) - K[T0, :] @ Phi[:, T0]\n","             ) @ x0[T0] + K[T0, :] @ y  # x_init\n","    yRes = y - Phi[:, T0] @ x[T0]  # yRes\n","\n","    # Variables for LP:\n","    c = cvxopt.matrix(np.ones(2*n), (2*n, 1), 'd')\n","    F = np.block([[Phi.T.dot(Phi), -Phi.T.dot(Phi)]])\n","    dRes = Phi.T.dot(yRes)\n","    G = np.block([[-np.identity(2*n)],\n","                  [F],\n","                  [-F]])\n","    G = cvxopt.matrix(G, (4*n, 2*n), 'd')\n","    h = np.block([np.zeros(2*n),\n","                  dRes + lamb*np.ones(n),\n","                  -dRes + lamb*np.ones(n)])\n","    h = cvxopt.matrix(h, (4*n, 1), 'd')\n","    xsol = cvxopt.solvers.lp(c, G, h)\n","    xsol = np.array(xsol['x'])\n","    xsol = xsol[:n]-xsol[n:]  # Note! This solution is 2-d.\n","    xsol = xsol[:, 0]\n","    x += xsol  # x_CSres\n","\n","    # Detect:\n","    Tdet = list(set(T0) | set(np.arange(n)[np.abs(x) > alpha]))\n","    if set(Tdet) == set(T0):\n","        pass\n","    else:\n","        x = np.zeros(n)\n","        x[Tdet] = conjGrad(Phi[:, Tdet].T.dot(\n","            Phi[:, Tdet]), Phi[:, Tdet].T.dot(y))\n","        # x_det\n","    # Delete:\n","    Tt = list(set(Tdet) - set(np.arange(n)[np.abs(x) <= alphaDel]))\n","    if set(Tt) == set(T0):\n","        P1 = P0\n","    else:\n","        x = np.zeros(n)  # x_final\n","        x[Tt] = conjGrad(Phi[:, Tt].T.dot(Phi[:, Tt]), Phi[:, Tt].T.dot(y))\n","        P1 = np.zeros((n, n))\n","        P1[Tt, Tt] = sigma2 * np.linalg.inv(Phi[:, Tt].T @ Phi[:, Tt])\n","    return (x, P1, Tt)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 3.2.2 动态 KF-CS"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["def KFCSResidual(Y: np.ndarray, Phi: np.ndarray, x0: np.ndarray,\n","                 T0=[],\n","                 P0=None, sigma2Sys=0.01, sigma2=0.01, lamb=0.1,\n","                 alpha=0.05, alphaDel=0.15,):\n","    \"\"\"\n","    Return signal sequence reconstruction for observed `Y`.\n","    \"\"\"\n","    m, N = Y.shape  # Sequence length.\n","    assert m == Phi.shape[0]\n","    n = Phi.shape[1]\n","    if T0 == []:\n","        T0 = list(getSupp(x0))\n","    if P0 is None:\n","        P0 = np.zeros((n, n))\n","        P0[T0, T0] = sigma2 * np.linalg.inv(Phi[:, T0].T @ Phi[:, T0])\n","    X = np.zeros((n, N))\n","    for t in range(N):\n","        x0, P0, T0 = KFCSResidualStatic(\n","            Y[:, t], Phi, x0, T0, P0, sigma2Sys, sigma2, lamb, alpha, alphaDel)\n","        X[:, t] = x0\n","    print('KFCSresidual Succeeded.')\n","    return X\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 3.3 Dynamic Reg-mod-BPDN\n","### 3.3.1 静态核 DRegModBPDN"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["def dynamicRegModBPDNStatic(\n","        y: np.ndarray, Phi: np.ndarray, x0=None, T0=[],\n","        gamma=1., lamb=1., alpha=0.1):\n","    '''\n","    return (xEsti, TEsti). \\n\n","    `alpha`: Detection param.\n","    '''\n","    n = Phi.shape[1]\n","    x = regModBPDN(y, Phi, T0, x0, gamma, lamb)\n","    # Simple supp detection:\n","    Tt = np.arange(n)[np.abs(x) > alpha]\n","\n","    return (x, Tt)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 3.3.2 动态 DRegModBPDN"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["def dynamicRegModBPDN(\n","    Y: np.ndarray, Phi: np.ndarray, x0=None, T0=[],\n","    gamma=1., lamb=1., alpha=0.1\n","):\n","    '''\n","    Return signal sequence reconstruction for observed `Y`. \\n\n","    `alpha`: Simple detection param.\n","    '''\n","    m, N = Y.shape  # Sequence length.\n","    assert m == Phi.shape[0]\n","    n = Phi.shape[1]\n","    if T0 == []:\n","        T0 = list(getSupp(x0))\n","    X = np.zeros((n, N))\n","    for t in range(N):\n","        x0, T0 = dynamicRegModBPDNStatic(\n","            Y[:, t], Phi, x0, T0, gamma, lamb, alpha)\n","        X[:, t] = x0\n","    print('DynamicRegModBPDN Succeeded.')\n","    return X\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 3.4 Mod-BPDN-residual\n","### 3.4.1 静态核 MBR\n","借用RegModBPDN, 将其中的reg项忽略即退化为ModBPDN."]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["def modBPDNResidualStatic(\n","        y: np.ndarray, Phi: np.ndarray, x0=None, T0=[], gamma=1.,\n","        alpha=0.1\n","):\n","    '''\n","    return (xEsti, TEsti). \\n\n","    `alpha`: Simple detection threshold.\n","    '''\n","    n = Phi.shape[1]\n","    if x0 is None:\n","        x0 = np.zeros(n)\n","    yRes = y - Phi @ x0\n","    xRes = regModBPDN(yRes, Phi, T0, gamma)\n","    x = x0 + xRes\n","    # Simple detection:\n","    Tt = np.arange(n)[np.abs(x) > alpha]\n","\n","    return (x, Tt)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 3.4.2 动态 MBR"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["def modBPDNResidual(Y:np.ndarray, Phi:np.ndarray, x0=None,\n","                    T0=[], gamma=1., alpha=0.1):\n","    '''\n","    `alpha`: Detection param. \\n \n","    return signal sequence reconstruction from observed `Y`.\n","    '''\n","    m, N = Y.shape  # Sequence length.\n","    assert m == Phi.shape[0]\n","    n = Phi.shape[1]\n","    if T0 == []:\n","        T0 = list(getSupp(x0))\n","    X = np.zeros((n, N))\n","    for t in range(N):\n","        x0, T0 = modBPDNResidualStatic(\n","            Y[:, t], Phi, x0, T0, gamma, alpha)\n","        X[:, t] = x0\n","    print('ModBPDNResidual Succeeded.')\n","    return X\n","    "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 3.5 Streaming mod-wl1\n","### 3.5.1 静态核 StrModWl1"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["def streamingModWl1Static(y: np.ndarray, Phi: np.ndarray, x0=None,\n","                          gamma=1., eps=1e-6):\n","    '''\n","    return xEsti. \\n\n","    `eps`: Avoid zero division.\n","    '''\n","    n = Phi.shape[1]\n","    if x0 is None:\n","        x0 = np.zeros(n)\n","    beta = n * (x0 @ x0)/((np.sum(np.abs(x0))+eps)**2)\n","    w = gamma / (beta * np.abs(x0) + 1)\n","\n","    # Variables for QP:\n","    posNeg = np.block([[np.identity(n), -np.identity(n)]])\n","    P = 0.5 * posNeg.T @ Phi.T @ Phi @ posNeg\n","    P = cvxopt.matrix(P,(2*n,2*n),'d')\n","    q = posNeg.T @ (w - Phi.T @ y)\n","    q = cvxopt.matrix(q, (2*n, 1), 'd')\n","    G = -np.identity(2*n)\n","    G = cvxopt.matrix(G, (2*n, 2*n), 'd')\n","    h = np.zeros(2*n)\n","    h = cvxopt.matrix(h, (2*n, 1), 'd')\n","    xsol = cvxopt.solvers.qp(P, q, G, h)\n","    xsol = np.array(xsol['x'])\n","    xsol = xsol[:n]-xsol[n:]  # Note! This solution is 2-d.\n","    xsol = xsol[:, 0]\n","    x = xsol\n","\n","    return x\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 3.5.2 动态 StrModWl1"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["def streamingModWl1(Y: np.ndarray, Phi: np.ndarray, x0=None,\n","                    gamma=1., eps=1e-6, **kwargs):\n","    '''\n","    `eps`: Avoid zero division. \\n \n","    return signal sequence reconstruction from observed `Y`.\n","    '''\n","    m, N = Y.shape  # Sequence length.\n","    assert m == Phi.shape[0]\n","    n = Phi.shape[1]\n","    # No need for T0.\n","    X = np.zeros((n, N))\n","    for t in range(N):\n","        x0 = streamingModWl1Static(\n","            Y[:, t], Phi, x0, gamma, eps)\n","        X[:, t] = x0\n","    print('StreamingModWl1 Succeeded.')\n","    return X\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"3ecbd6e174ff4a7098b0b778d486ae95","deepnote_cell_type":"markdown"},"source":["# 4(executable) 数值测试"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4.1 Rademacher signals with Gaussian noise test\n","### 4.1.1 Static CS"]},{"cell_type":"code","execution_count":60,"metadata":{"cell_id":"acb4955329f0451bb7c9b5bf3e435d6b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":8,"execution_start":1680842307529,"source_hash":"4e3fb9c2"},"outputs":[],"source":["# Generate A, X.\n","np.random.seed(42)\n","A = randSampMat(300, 1000)\n","XX = randSparseSignal(n=1000, s=30, size=20, returnSupports=True)\n","X, Supps = XX['Signals'], XX['Supports']\n","del XX\n","Y = np.dot(A, X[:, :10])\n"]},{"cell_type":"code","execution_count":61,"metadata":{"cell_id":"d51cc2a95b3d4a44bada51ae196e444f","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":342,"execution_start":1680842312030,"source_hash":"9a11c6ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Max singular value: 1.3534611\n","Min singular value: 0.65051883\n"]},{"data":{"text/plain":["0.3534611463546753"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["# Mixed test. 需要的模拟次数可以远小于monteCarlo方法, 准确度也更大.\n","RIPTest(A, 30).mixedMethod(1000)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### 4.1.1.1 IHT-PKS"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Exec! (Old.数值测试)\n","Could serve for reference."]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["     pcost       dcost       gap    pres   dres\n"," 0: -1.3861e+01  1.2351e+01  3e+03  5e+01  3e+00\n"," 1:  8.8466e+00 -3.8210e+01  5e+01  5e-01  3e-02\n"," 2: -7.2986e+00 -1.3785e+01  6e+00  6e-15  5e-15\n"," 3: -1.1824e+01 -1.3683e+01  2e+00  2e-15  2e-15\n"," 4: -1.2613e+01 -1.3638e+01  1e+00  1e-15  1e-15\n"," 5: -1.3314e+01 -1.3640e+01  3e-01  1e-15  7e-16\n"," 6: -1.3591e+01 -1.3624e+01  3e-02  1e-15  7e-16\n"," 7: -1.3619e+01 -1.3622e+01  3e-03  9e-16  7e-16\n"," 8: -1.3622e+01 -1.3622e+01  2e-04  8e-16  7e-16\n"," 9: -1.3622e+01 -1.3622e+01  7e-06  8e-16  7e-16\n","Optimal solution found.\n","0.07013603381944279\n"]}],"source":["# regModBPDN\n","x = regModBPDN(Y[:, 0], A, gamma=0.01)\n","# 允许index out of range.\n","err = np.linalg.norm(x - X[:, 0])\n","print(err)\n"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["     pcost       dcost       gap    pres   dres   k/t\n"," 0: -6.8390e-14 -6.0000e+00  7e+03  1e+00  1e+00  1e+00\n"," 1:  1.3699e+02  1.3548e+02  2e+03  5e-01  4e-01  1e+00\n"," 2:  1.1865e+02  1.1807e+02  9e+02  2e-01  2e-01  7e-01\n"," 3:  9.8492e+01  9.8486e+01  5e+01  1e-02  1e-02  7e-02\n"," 4:  1.0005e+02  1.0005e+02  4e+00  2e-03  1e-03  3e-03\n"," 5:  1.0157e+02  1.0157e+02  7e-01  3e-04  3e-04  8e-04\n"," 6:  1.0174e+02  1.0174e+02  2e-01  1e-04  9e-05  3e-04\n"," 7:  1.0180e+02  1.0180e+02  9e-02  4e-05  4e-05  1e-04\n"," 8:  1.0182e+02  1.0182e+02  6e-02  3e-05  2e-05  6e-05\n"," 9:  1.0183e+02  1.0183e+02  2e-02  7e-06  6e-06  1e-05\n","10:  1.0184e+02  1.0184e+02  7e-03  3e-06  3e-06  6e-06\n","11:  1.0184e+02  1.0184e+02  1e-03  7e-07  5e-07  1e-06\n","12:  1.0184e+02  1.0184e+02  7e-05  3e-08  3e-08  6e-08\n","Optimal solution found.\n","0.08012917775931015\n"]}],"source":["# wl1\n","x = weightedl1(Y[:, 0], A, T0=Supps[:, 0][:20], lamb=1e-2)\n","# 允许index out of range.\n","err = np.linalg.norm(x - X[:, 0])\n","print(err)\n"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["     pcost       dcost       gap    pres   dres   k/t\n"," 0: -8.5038e-11 -6.0000e+00  2e+06  1e+00  1e-03  1e+00\n"," 1:  6.8710e+04  7.0453e+04  3e+06  1e+00  9e-04  2e+03\n"," 2:  2.3171e+05  2.3236e+05  1e+06  3e-01  3e-04  7e+02\n"," 3:  2.6847e+05  2.6891e+05  6e+05  2e-01  2e-04  4e+02\n"," 4:  2.9286e+05  2.9292e+05  7e+04  2e-02  2e-05  6e+01\n"," 5:  2.9710e+05  2.9710e+05  7e+03  3e-03  2e-06  4e+00\n"," 6:  2.9915e+05  2.9915e+05  1e+03  5e-04  4e-07  1e+00\n"," 7:  2.9947e+05  2.9947e+05  3e+02  1e-04  1e-07  3e-01\n"," 8:  2.9956e+05  2.9956e+05  8e+01  4e-05  3e-08  7e-02\n"," 9:  2.9958e+05  2.9958e+05  3e+01  2e-05  1e-08  3e-02\n","10:  2.9958e+05  2.9958e+05  1e+01  7e-06  6e-09  1e-02\n","11:  2.9959e+05  2.9959e+05  9e+00  4e-06  3e-09  7e-03\n","12:  2.9959e+05  2.9959e+05  4e+00  2e-06  2e-09  4e-03\n","13:  2.9959e+05  2.9959e+05  4e-01  2e-07  1e-10  3e-04\n","14:  2.9959e+05  2.9959e+05  3e-02  2e-08  1e-11  3e-05\n","Optimal solution found.\n","Iter: 0 ChangeRate: 0.9999999999999998\n","     pcost       dcost       gap    pres   dres   k/t\n"," 0: -9.0495e-11 -6.0000e+00  2e+06  1e+00  1e-03  1e+00\n"," 1:  8.1530e+01  1.0365e+02  2e+06  1e+00  9e-04  3e+01\n"," 2: -3.6184e+01 -3.3342e+01  8e+04  5e-02  4e-05  3e+00\n"," 3: -2.4796e+01 -2.4660e+01  4e+03  2e-03  2e-06  1e-01\n"," 4:  7.2412e+00  7.2836e+00  7e+01  4e-05  3e-08  4e-02\n"," 5:  2.9567e+01  2.9568e+01  1e+00  9e-07  7e-10  9e-04\n"," 6:  2.9953e+01  2.9954e+01  2e-01  1e-07  1e-10  1e-04\n"," 7:  2.9981e+01  2.9981e+01  9e-02  5e-08  4e-11  6e-05\n"," 8:  2.9988e+01  2.9988e+01  6e-02  3e-08  3e-11  4e-05\n"," 9:  3.0006e+01  3.0006e+01  1e-02  7e-09  6e-12  9e-06\n","10:  3.0009e+01  3.0009e+01  5e-03  3e-09  3e-12  4e-06\n","11:  3.0011e+01  3.0011e+01  7e-04  4e-10  4e-13  6e-07\n","12:  3.0011e+01  3.0011e+01  1e-04  8e-11  7e-14  1e-07\n","13:  3.0011e+01  3.0011e+01  2e-06  1e-12  2e-15  1e-09\n","Optimal solution found.\n","Iter: 1 ChangeRate: 0.0010275437246629433\n","     pcost       dcost       gap    pres   dres   k/t\n"," 0: -7.5488e-11 -6.0000e+00  2e+06  1e+00  1e-03  1e+00\n"," 1:  7.9025e+01  1.0128e+02  2e+06  1e+00  9e-04  3e+01\n"," 2: -4.7538e+01 -4.1969e+01  2e+05  9e-02  7e-05  6e+00\n"," 3: -3.5301e+01 -3.5244e+01  2e+03  9e-04  8e-07  6e-02\n"," 4:  1.5495e+01  1.5520e+01  5e+01  3e-05  2e-08  3e-02\n"," 5:  2.9754e+01  2.9755e+01  9e-01  5e-07  4e-10  5e-04\n"," 6:  2.9933e+01  2.9933e+01  2e-01  1e-07  1e-10  1e-04\n"," 7:  2.9946e+01  2.9946e+01  1e-01  8e-08  7e-11  9e-05\n"," 8:  2.9982e+01  2.9982e+01  4e-02  2e-08  2e-11  3e-05\n"," 9:  2.9992e+01  2.9992e+01  1e-02  7e-09  5e-12  8e-06\n","10:  2.9995e+01  2.9995e+01  5e-03  3e-09  2e-12  4e-06\n","11:  2.9997e+01  2.9997e+01  8e-04  5e-10  4e-13  6e-07\n","12:  2.9997e+01  2.9997e+01  1e-04  6e-11  5e-14  9e-08\n","13:  2.9997e+01  2.9997e+01  1e-06  7e-13  2e-15  1e-09\n","Optimal solution found.\n","Iter: 2 ChangeRate: 2.0509154720515753e-08\n","0.07262162150312232\n"]}],"source":["# rwl1\n","x = reweightedl1(Y[:, 0], A, lamb=1e-2, showChangeRate=True)\n","# 允许index out of range.\n","err = np.linalg.norm(x - X[:, 0])\n","print(err)\n"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["     pcost       dcost       gap    pres   dres   k/t\n"," 0:  7.6534e-14 -8.0000e+00  9e+03  1e+00  1e+00  1e+00\n"," 1:  1.3650e+02  1.3441e+02  2e+03  4e-01  4e-01  1e+00\n"," 2:  1.2304e+02  1.2186e+02  1e+03  3e-01  2e-01  9e-01\n"," 3:  9.6427e+01  9.6261e+01  3e+02  7e-02  6e-02  4e-01\n"," 4:  9.5616e+01  9.5601e+01  1e+01  3e-03  3e-03  8e-03\n"," 5:  9.9352e+01  9.9349e+01  2e+00  5e-04  5e-04  1e-03\n"," 6:  9.9656e+01  9.9655e+01  6e-01  2e-04  2e-04  5e-04\n"," 7:  9.9764e+01  9.9764e+01  2e-01  8e-05  7e-05  2e-04\n"," 8:  9.9805e+01  9.9805e+01  9e-02  3e-05  3e-05  7e-05\n"," 9:  9.9823e+01  9.9823e+01  4e-02  1e-05  1e-05  3e-05\n","10:  9.9835e+01  9.9835e+01  9e-03  3e-06  3e-06  6e-06\n","11:  9.9838e+01  9.9838e+01  2e-03  9e-07  8e-07  2e-06\n","12:  9.9838e+01  9.9838e+01  2e-04  8e-08  7e-08  1e-07\n","13:  9.9838e+01  9.9838e+01  1e-05  5e-09  4e-09  8e-09\n","Optimal solution found.\n","0.08167599195576739\n"]}],"source":["# ModCS\n","x = ModCS(Y[:, 0], A, T0=Supps[:, 0][:20], lamb=1e-2)\n","# 允许index out of range.\n","err = np.linalg.norm(x - X[:, 0])\n","print(err)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"3dcdb48677054412b3726cd15ea5fc90","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":614,"execution_start":1680842333870,"source_hash":"6074544c"},"outputs":[],"source":["# IRLSPKS\n","x = IRLSPKS(Y[:, 0], A, showIfMaxIter=True, showChangeRate=True)\n","err = np.linalg.norm(x - X[:, 0])\n","print(err)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"26c4ce9e4df741c1af074590be6a27fc","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":94,"execution_start":1680842342088,"source_hash":"6ebc106"},"outputs":[],"source":["# RWLSSl0PKS\n","x = RWLSSl0PKS(Y[:, 0], A, showIfMaxIter=True, showChangeRate=True)\n","err = np.linalg.norm(x - X[:, 0])\n","print(err)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"18bbdc4507ef4942a50f82c58801a69a","deepnote_cell_type":"code"},"outputs":[],"source":["# CosampPKS\n","ErrCosampPKS = []\n","for j in range(Y.shape[1]):\n","    x = CosampPKS(Y[:, j], A, 50, maxIter=100, showIfMaxIter=True)\n","    # 看看误差.\n","    err = np.linalg.norm(x - X[:, j])\n","    ErrCosampPKS.append(err)\n","    print(j, 'Err:', err)\n","else:\n","    print('Mean Err:', np.mean(ErrCosampPKS))\n","\n","# IHTPKS\n","ErrIHTPKS = []\n","for j in range(Y.shape[1]):\n","    x = IHTPKS(Y[:, j], A, 50, maxIter=100, showIfMaxIter=True)\n","    # 看看误差.\n","    err = np.linalg.norm(x - X[:, j])\n","    ErrIHTPKS.append(err)\n","    print(j, 'Err:', err)\n","else:\n","    print('Mean Err:', np.mean(ErrIHTPKS))\n","\n","# OMPPKS\n","# ErrOMPPKS = []\n","# for j in range(Y.shape[1]):\n","#     x = OMPPKS(Y[:,j],A,maxIter=100,showIfMaxIter=True)\n","#     #看看误差.\n","#     err = np.linalg.norm(x - X[:,j])\n","#     ErrOMPPKS.append(err)\n","#     print(j,'Err:',err)\n","# else:\n","#     print('Mean Err:',np.mean(ErrOMPPKS))\n","\n","plt.plot(ErrCosampPKS, ls='-.', label='cosamp')\n","plt.axhline(np.mean(ErrCosampPKS), ls=':', label='mean cosamp')\n","plt.plot(ErrIHTPKS, ls='--', label='iht')\n","plt.axhline(np.mean(ErrIHTPKS), ls='-', label='mean iht')\n","# plt.plot(ErrOMPPKS,label='omp')\n","plt.legend()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"dff9c33f05fd4d75b1fb1e4252ed5d37","deepnote_cell_type":"code"},"outputs":[],"source":["# Test 待改20230402\n","# def test(Y,X,s,times=1000, func=IHTPKS, priorSuppRatio=0.2, SuppsReal=None, **kwargs):\n","#     \"\"\"\n","#     Run `times` times of `func` function\n","#         given `Y`=[y1,...,yt], `X`=[x1,...,xt],\n","#         use `priorSuppRatio`(from 0 to 1) instead of `T0`,\n","#         `SuppsReal`: aranged by cols, if `None` then supps(X)(`s` needed),\n","#         and `**kwargs` as other keyword arguments.\n","\n","#     Return the results in an array.\n","#     \"\"\"\n","#     Results = []\n","#     if SuppsReal is None:\n","#         SuppsReal = np.zeros((s,X.shape[1])).astype('int')\n","#         for j in range(X.shape[1]):\n","#             SuppsReal[:,j] = np.argsort(np.abs(X[:,j]))[:-(s+1):-1] #兼容compressible signal.\n","\n","#     for t in range(times):\n","#         T0 = np.random.choice(SuppsReal[:,t],int(round(s*priorSuppRatio,0)),replace=False)\n","#         Results.append(func(y=Y[:,t],xReal=X[:,t],T0=T0,s=s,**kwargs))\n","#     return Results\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"89647f443e8a432e91b64678e793a095","deepnote_cell_type":"markdown"},"source":["# Exec! (Debug area)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"942a2a8b145744c3aa69cf2126295b78","kernelspec":{"display_name":"bachelorThesis","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"0fa5ea0a09a8cd9d0aa4e6bbb526a74c2e7a420b3d09cd1311bf211743dd137b"}}},"nbformat":4,"nbformat_minor":0}
