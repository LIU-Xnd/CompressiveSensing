{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log\n",
    "## 20230331\n",
    "mod-(reg)-BPDN可以转化为一个二次规划问题, 用qp()解决.\n",
    "`cvxopt.solvers.qp()`\n",
    "## 20230401\n",
    "建议不要过度封装. 每个算法尽量展开写出.另外不要过度输出,可以只输出信号估计,而误差等可以不输出,而是改为在别的地方重新计算.|尝试加入haltingRule=('rIterErr',eps), 但不会以这种封装的方式, 而是针对个别算法.|以后要测试算法性能,考虑收敛时(因此要用'rIterErr'停机判定)取得的误差最小值,以及达到收敛需要的迭代次数.总的来看,'rIterErr'可能是比'rSampErr'更好的停机判据.\n",
    "## 20230402\n",
    "大改代码. 把算法统一到各自的功能中,去掉多余的参数,例如先知信号等.将停机法则统一为相对更新率收敛至`eps=1e-6`.由于要比较迭代次数,可以设置可选输出`returnIter=True`.\n",
    "题目含有'Exec!'的为直接可执行代码区域,注意绕开.\n",
    "## 20230404\n",
    "把所有向量维数统一为`n`,之后可能的时间序列长度记为`N`.\n",
    "## 20230405\n",
    "写完IRLSPKS. 算法性能比较可以从时间、先验贡献、RIP、重建误差、准确率和召回率、广义准确率和召回率(s-稀疏化后)等, 待补充."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations as cb\n",
    "import cvxopt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 预备函数\n",
    "## 1.1 随机采样阵生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机采样阵生成\n",
    "def randSampMat(m,n):\n",
    "    \"\"\"\n",
    "    Return m*n sampling matrix.\n",
    "    Use type `np.float32`.\n",
    "    \"\"\"\n",
    "    #用高斯分布抽样, 列单位化.\n",
    "    A = np.random.randn(m,n).astype(np.float32)\n",
    "    for j in range(A.shape[1]):\n",
    "        A[:,j] = A[:,j] / np.sqrt(A[:,j].dot(A[:,j]))\n",
    "    return A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 共轭梯度法\n",
    "(Iterative) Conjugate gradient method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjGrad(A,b,maxIter=-1,x=\"0\",eps=1e-6,showChangeRate=False):\n",
    "    \"\"\"\n",
    "    迭代的共轭梯度法. 要求A实正定对称.\n",
    "    `x`:初始点.\n",
    "    收敛相对误差|Δx[t]|/|x[t-1]|被`eps`控制.\n",
    "    方法优点: 迭代至多进行k=len(b)次. A事先计算出,控制迭代次数,则复杂度O(k^2).\n",
    "    不吝啬迭代则O(k^3).\n",
    "    \"\"\"\n",
    "    k = A.shape[0] # 行/列数。\n",
    "    if maxIter==-1:\n",
    "        maxIter = k\n",
    "    if x=='0':\n",
    "        x = np.zeros(k)\n",
    "    r = b - np.dot(A,x)\n",
    "    p = r\n",
    "    r2old = r.dot(r)\n",
    "    for i in range(maxIter):\n",
    "        Ap = A.dot(p)\n",
    "        alpha = r2old / (p.dot(Ap))\n",
    "        xOld = x\n",
    "        x = x + alpha * p\n",
    "        r = r - alpha * Ap\n",
    "        r2new = r.dot(r)\n",
    "        changeRate = np.sqrt((x-xOld).dot(x-xOld)/(eps**2 + x.dot(x)))\n",
    "            #相对迭代误差(改进率).\n",
    "        if showChangeRate:\n",
    "            print('Iter',i,':',changeRate)\n",
    "        if changeRate < eps:\n",
    "            break\n",
    "        p = r + (r2new/r2old)*p\n",
    "        r2old = r2new\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 限制等距常数估计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIP测试.\n",
    "class RIPtest:\n",
    "    def __init__(self,A,s):\n",
    "        \"\"\"\n",
    "        Return possible delta_s given matrix `A` and sparsity `s`.\n",
    "\n",
    "        Contain 2 methods:\n",
    "            `RIPtest(A,s).monteCarlo(nVec,show)`: Monte Carlo method;\n",
    "            `RIPtest(A,s).singularValue()`: singularValue method.\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        self.s = s\n",
    "    #         \n",
    "    # \n",
    "    # \n",
    "    #                 \n",
    "    # Monte-Carlo method.\n",
    "    def monteCarlo(self, nVec=1e5, show=True): # 这是一个对象方法.\n",
    "        \"\"\"\n",
    "        Return possible delta_s given matrix `A` and sparsity `s`. \\n\n",
    "        `nVec`: Number of vectors to test. \\n\n",
    "        `show`: Whether to draw the distribution of amplifications. \\n\n",
    "        Running time: \\n\n",
    "            O(nVec=10000,n=10000,m=400)~70sec; \\n\n",
    "            O(nVec=5000,n=5000,m=200)~10sec; \\n\n",
    "            O(nVec=100000,n=200,m=50)~3sec.\n",
    "        \"\"\"\n",
    "        n = self.A.shape[1]\n",
    "        nVec = int(nVec) # 转化形如`1e5`的输入.\n",
    "        V =  np.zeros((n,nVec),order='F',dtype=np.float32) # 由多个s-稀疏的列向量组成. \n",
    "        Supps = np.array([np.random.choice(range(n),self.s,replace=False) for i in range(nVec)])\n",
    "            # 随机抽取支集, 存为每一行.\n",
    "        Entries = np.array([np.random.randn(self.s).astype(np.float32) for i in range(nVec)])\n",
    "            # 随机赋予支集项的值, 存为每一行. 未正规化.\n",
    "        for j in range(nVec):\n",
    "            # supp = Supps[j]\n",
    "            # entries = Entries[j]\n",
    "            V[Supps[j],j] = Entries[j]/np.linalg.norm(Entries[j])\n",
    "        V = np.dot(self.A,V)\n",
    "            # 象.\n",
    "        Amplifications = np.array(list(map(lambda v:np.linalg.norm(v), np.transpose(V))))\n",
    "        ampMax = np.max(Amplifications); delta1 = ampMax-1\n",
    "        ampMin = np.min(Amplifications); delta2 = 1-ampMin\n",
    "        delta = max(delta1,delta2)\n",
    "\n",
    "        if show==True:\n",
    "        # 用Gaussian近似检测delta估计是否超出3-sigma,若是,则认为delta即使再估计也不会显著增加,基本准确.\n",
    "            var = np.var(Amplifications)\n",
    "            mean = np.mean(Amplifications)\n",
    "            threeSigma = 3*np.sqrt(var)\n",
    "            ThreeSigmaPoints = [mean - threeSigma, mean + threeSigma]\n",
    "            Xnorm = np.linspace(ThreeSigmaPoints[0],ThreeSigmaPoints[1],100)\n",
    "            Ynorm = stats.norm.pdf((Xnorm-mean)/np.sqrt(var))/np.sqrt(var)\n",
    "\n",
    "            plt.hist(Amplifications,bins=100,density=True,label='Amplifications')\n",
    "            plt.plot(Xnorm,Ynorm,'r:',label='Gaussian Reference')\n",
    "            plt.axvline(ThreeSigmaPoints[0],linestyle='-.',color='g',label='-3 sigma')\n",
    "            plt.axvline(ThreeSigmaPoints[1],linestyle='--',color='m',label='+3 sigma')\n",
    "            plt.xlabel('Amp.')\n",
    "            plt.ylabel('Density')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            print(\"3-sigma points: [1 - {:}, 1 + {:}]\".format(1-ThreeSigmaPoints[0],ThreeSigmaPoints[1]-1))\n",
    "            \n",
    "            if delta==delta1:\n",
    "                side = 'Right'\n",
    "            else:\n",
    "                side = 'Left'\n",
    "            print(\"Side:\",side)\n",
    "        return delta\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    # SingularValue method.\n",
    "    def singularValue(self, SAFECODE, showSingularValues=True, mode='memory-saving'):\n",
    "        \"\"\"\n",
    "        有内存泄漏危险, 勿用! \\n\n",
    "        确认使用时输入参数`SAFECODE=CONFIRM`. \\n\n",
    "        Return delta_s. \\n\n",
    "        `showSingularValues`: Whether to show the two max&min singularValues of all submatrices. \\n\n",
    "        Running time: \\n\n",
    "            `mode='memory-saving'`: O(n=200,m=20,s=3)~30sec; O(n=2000,m=20,s=2)~39sec; O(n=2000,m=20,s=3)~ >5min. \\n\n",
    "            `mode='fast'`: O(n=200,m=20,s=3)~23sec; O(n=2000,m=20,s=2)~27sec; O(n=2000,m=20,s=3)~ >2min(MemoryError). \\n        \n",
    "        建议: \\n\n",
    "            1, 采用分布式计算, 因为耗时关于s指数级增长; \\n\n",
    "            2, 改用Monte-Carlo方法, 其估计概率已足够大; \\n\n",
    "            3, `fast`模式对于稍大矩阵几乎不能用, 基本上会报错`MemoryError`.\n",
    "        \"\"\"\n",
    "        if SAFECODE!='CONFIRM':\n",
    "            print('Not safe!')\n",
    "            return\n",
    "        n = self.A.shape[1]\n",
    "        # 以时间换空间: 使用s个指针Pointers, 列举指针组合.\n",
    "        if mode=='memory-saving':\n",
    "            PtrCombinations = cb(range(n),self.s)\n",
    "            maxSv, minSv = 1, 1\n",
    "            for ptr in PtrCombinations:\n",
    "                ptr = list(ptr)\n",
    "                Svs = np.sqrt(np.linalg.eigvals(self.A[:,ptr].T.dot(self.A[:,ptr]))) \n",
    "                    # `Svs` for 'Singular Values'.\n",
    "                    # Only accept float32+ type.\n",
    "                maxSv = max(np.max(Svs),maxSv)\n",
    "                minSv = min(np.min(Svs),minSv)\n",
    "        # 以空间换时间.\n",
    "        elif mode=='fast':\n",
    "            Submatrices = np.array(list(cb(self.A.transpose(),self.s)))\n",
    "            Svs = np.sqrt(np.linalg.eigvals(Submatrices.T.dot(Submatrices)))\n",
    "\n",
    "            maxSv = max(Svs)\n",
    "            minSv = min(Svs)\n",
    "\n",
    "        delta = max(maxSv - 1, 1 - minSv)\n",
    "        if showSingularValues==True:\n",
    "            print('Max singular value:', maxSv)\n",
    "            print('Min singular value:', minSv)\n",
    "        return delta\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    # A mixed version.\n",
    "    def mixedMethod(self, times=10000, showSingularValues=True):\n",
    "        \"\"\"\n",
    "        A better and safe mixed version of Monte-Carlo & SingularValue.\n",
    "        \"\"\"\n",
    "        n = self.A.shape[1]\n",
    "        maxSv, minSv = 1, 1\n",
    "        for t in range(times):\n",
    "            comb = np.random.choice(range(n),self.s,replace=False)\n",
    "            submatrix = self.A[:,comb].astype(np.float32)\n",
    "            Svs = np.linalg.eigvals(np.dot(submatrix.transpose(),submatrix))\n",
    "                # `Svs` for 'Singular Values'.\n",
    "                # Only accept float32+ type.\n",
    "            maxSv = max(np.sqrt(np.max(Svs)),maxSv)\n",
    "            minSv = min(np.sqrt(np.min(Svs)),minSv)\n",
    "\n",
    "        delta = max(maxSv - 1, 1 - minSv)\n",
    "        if showSingularValues==True:\n",
    "            print('Max singular value:', maxSv)\n",
    "            print('Min singular value:', minSv)\n",
    "        return delta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 硬阈值函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 硬阈值函数\n",
    "def hardThreshold(x,s,T0=[]):\n",
    "    \"\"\"\n",
    "    Return x with its largest s-k entries and k entries indexed in T0, the rest set to 0.\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    k = len(T0)\n",
    "    comparingVec = x.copy()\n",
    "    comparingVec[T0]=0 #去掉支集项以寻找剩余元素的s-k个最大值.\n",
    "    delta = np.abs(comparingVec).argsort()[:-(s-k+1):-1] #返回s-k个绝对最大值的索引.\n",
    "    supp = np.append(T0, delta).astype('int64')\n",
    "    new = np.zeros(n)\n",
    "    new[supp]=x[supp]\n",
    "\n",
    "    return new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 取支集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSupp(x:np.ndarray,s:int=-1):\n",
    "    \"\"\"\n",
    "    Return supp(x_s) corresponding to from Largest to Smallest. \\n\n",
    "    If `s` left default, -1, then s=sum(x!=0).\n",
    "    \"\"\"\n",
    "    if s==-1:\n",
    "        s = sum(1 - np.isclose(x,0))\n",
    "    return np.abs(x).argsort()[:-s-1:-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Deprecated). errAnalyze()\n",
    "可以作以后误差分析的参考."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def errAnalyze(xReal,suppReal,x1,n,s,showPrecisionAndRecall,iterCount,eps,y,err,yNorm):\n",
    "#     \"\"\"\n",
    "#     errAnalyze(xReal,suppReal,x1,n,s,showPrecisionAndRecall,iterCount,eps,y,err,yNorm)\n",
    "#         -> dict(\n",
    "#             estimate,iterCount,eps,y,errY,relativeErrY,confusion\n",
    "#         )\n",
    "#     \"\"\"\n",
    "#     if not (xReal is None):\n",
    "#         if suppReal is None:\n",
    "#             suppReal = np.argsort(np.abs(xReal))[:-(s+1):-1] #兼容compressible signal.\n",
    "        \n",
    "#         # Compute confusion matrix.\n",
    "#         nPositive = np.sum(1-np.isclose(x1,0))\n",
    "#         nTruePositive = np.sum(1-np.isclose(x1[suppReal],0))\n",
    "#         nFalsePositive = nPositive - nTruePositive\n",
    "#         nNegative = n - nPositive\n",
    "#         nFalseNegative = np.sum(np.isclose(x1[suppReal],0))\n",
    "#         nTrueNegative = nNegative - nFalseNegative\n",
    "\n",
    "#         confusion = pd.DataFrame(np.array([\n",
    "#             [nTruePositive,nTrueNegative],\n",
    "#             [nFalsePositive,nFalseNegative]\n",
    "#         ]), columns=['positive','negative'],index=['true','false'])\n",
    "#         if showPrecisionAndRecall == True:\n",
    "#             print('precision:',nTruePositive/(nTruePositive + nFalsePositive))\n",
    "#             print('recall:',nTruePositive/(nTruePositive + nFalseNegative))\n",
    "\n",
    "#     else:\n",
    "#         confusion = None\n",
    "    \n",
    "#     return dict(\n",
    "#         estimate=x1,\n",
    "#         iterCount=iterCount,\n",
    "#         eps=eps,\n",
    "#         y=y,\n",
    "#         errY=err,\n",
    "#         relativeErrY=err/yNorm,\n",
    "#         confusion=confusion\n",
    "#     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 主要算法\n",
    "## 2.1 IHT-PKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IHT-PKS\n",
    "def IHTPKS(y:np.ndarray, Phi:np.ndarray, s:int, x0='0', T0=[], mu=1,\n",
    "           maxIter:int=100,eps=1e-6,\n",
    "           returnIter=False,\n",
    "           showIfMaxIter=False, showChangeRate=False):\n",
    "    \"\"\"\n",
    "    `mu`:Learning rate. \\n\n",
    "    Return signal estimate. \\n\n",
    "    If `returnIter`, return tuple(signalEsti,iter).\n",
    "    \"\"\"\n",
    "    n = Phi.shape[1] # signal length.\n",
    "    if x0=='0':\n",
    "        x0 = np.zeros(n)\n",
    "\n",
    "    for t in range(maxIter):\n",
    "        p = x0 + mu * Phi.T.dot(y - Phi.dot(x0)) # proxy.\n",
    "        x1 = hardThreshold(p,s,T0)\n",
    "        dx = x1-x0\n",
    "        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2)) \n",
    "        if showChangeRate:\n",
    "            print('Iter:',t,'ChangeRate:',changeRate) # Log.\n",
    "        if changeRate<eps:\n",
    "            iter = t\n",
    "            break\n",
    "        else:\n",
    "            x0 = x1\n",
    "    else: # Reach maxIter.\n",
    "        iter = maxIter-1\n",
    "        if showIfMaxIter:\n",
    "            print('Reach maxIter:',maxIter)\n",
    "    \n",
    "    if returnIter:\n",
    "        return (x1,iter)\n",
    "    else:\n",
    "        return x1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 OMP-PKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OMPPKS(y, Phi:np.ndarray, x0='0', T0=[],\n",
    "           maxIter:int=100, eps=1e-6,\n",
    "           returnIter=False,\n",
    "           showIfMaxIter=False, showChangeRate=False):\n",
    "    \"\"\"\n",
    "    Does not require sparsity 's'.\n",
    "    \"\"\"\n",
    "    # Init.\n",
    "    n = Phi.shape[1]\n",
    "    if x0=='0':\n",
    "        x0 = np.zeros(n)\n",
    "    supp = list(T0) # PKS.\n",
    "\n",
    "    # Iteration.\n",
    "    for t in range(maxIter):\n",
    "        p = Phi.T.dot(y - Phi.dot(x0)) # proxy.\n",
    "        j = np.argmax(np.abs(p))\n",
    "        if j not in supp:\n",
    "            supp.append(j)\n",
    "        x1 = np.zeros(n)\n",
    "        # Use conjGrad to solve lstsq problem.\n",
    "            # Note here the problem is |Phi.T.dot(Phi).dot(x)-Phi.T.dot(y)|->0.\n",
    "        x1[supp] = conjGrad(Phi[:,supp].T.dot(Phi[:,supp]),Phi[:,supp].T.dot(y))\n",
    "\n",
    "        dx = x1 - x0\n",
    "        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2))\n",
    "        if showChangeRate:\n",
    "            print('Iter:',t,'ChangeRate:',changeRate) # Log.\n",
    "        if changeRate < eps:\n",
    "            iter = t\n",
    "            break\n",
    "        else:\n",
    "            x0 = x1\n",
    "    else: # maxIter.\n",
    "        iter = maxIter-1\n",
    "        if showIfMaxIter:\n",
    "            print('Reach maxIter:',maxIter)\n",
    "\n",
    "    if returnIter:\n",
    "        return (x1,iter)\n",
    "    else:\n",
    "        return x1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 CoSaMP-PKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CosampPKS\n",
    "def CosampPKS(y:np.ndarray, Phi:np.ndarray, s:int, T0=[],\n",
    "            conjGradIter = -1,\n",
    "            maxIter:int=100,eps=1e-6,\n",
    "            returnIter=False,\n",
    "            showIfMaxIter=False, showChangeRate=False):\n",
    "    \"\"\"\n",
    "    Return signal estimate. \\n\n",
    "    If `returnIter`, return tuple(signalEsti,iter).\n",
    "\n",
    "    If `conjGradIter` left default, -1, then it iterates enough times.\n",
    "    \"\"\"\n",
    "    n = Phi.shape[1] # signal length.\n",
    "    T0 = list(T0)\n",
    "    x0 = np.zeros(n)\n",
    "    if len(T0)>0: # A priori.\n",
    "        x0[T0] = conjGrad(Phi[:,T0].T.dot(Phi[:,T0]),Phi[:,T0].T.dot(y),conjGradIter)\n",
    "    r = y - Phi[:,T0].dot(x0[T0]) # 感知残差.\n",
    "    K = s - len(T0) # 剩余稀疏度.\n",
    "\n",
    "    for t in range(maxIter):\n",
    "        p = Phi.T.dot(r) # proxy.\n",
    "        Omega = getSupp(p,2*K) # 2K-supp of proxy.\n",
    "        Tm = list(set(Omega) | set(getSupp(x0))) # Supp merge.\n",
    "        b = np.zeros(n)\n",
    "        b[Tm] = conjGrad(Phi[:,Tm].T.dot(Phi[:,Tm]),Phi[:,Tm].T.dot(y),conjGradIter)\n",
    "            # Elaborative solution.\n",
    "        A = b.copy()\n",
    "        A[T0] = 0 # Auxiliary.\n",
    "        x1 = np.zeros(n)\n",
    "        supp = list(set(T0)|set(getSupp(A,K)))\n",
    "        x1[supp] = b[supp]\n",
    "        r = y - Phi.dot(x1) \n",
    "\n",
    "        dx = x1 - x0\n",
    "        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2)) \n",
    "        if showChangeRate:\n",
    "            print('Iter:',t,'ChangeRate:',changeRate) # Log.\n",
    "        if changeRate<eps:\n",
    "            iter = t\n",
    "            break\n",
    "        else:\n",
    "            x0 = x1\n",
    "    else: # Reach maxIter.\n",
    "        iter = maxIter-1\n",
    "        if showIfMaxIter:\n",
    "            print('Reach maxIter:',maxIter)\n",
    "    \n",
    "    if returnIter:\n",
    "        return (x1,iter)\n",
    "    else:\n",
    "        return x1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 IRLS-PKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRLSPKS.\n",
    "def IRLSPKS(y:np.ndarray, Phi:np.ndarray, T0=[],\n",
    "            p:int=1, mu=1e-3, tau=1e-3,\n",
    "            conjGradIter=-1,\n",
    "            maxIter:int=100,eps=1e-6,\n",
    "            returnIter=False,\n",
    "            showIfMaxIter=False, showChangeRate=False):\n",
    "    \"\"\"\n",
    "    `p`: Norm number, in (0,1]. \\n\n",
    "    `mu`: Normalizing param. `sqrt(mu)/100`'s Minimum is `eps`. \\n\n",
    "    `tau`: Short for tau^(2-p) in the paper. Weighting param. \\n\n",
    "    Return signal estimate. \\n\n",
    "    If `returnIter`, return tuple:(signalEsti,iter). \\n\n",
    "    If `conjGradIter` left default, -1, then it iterates enough times.\n",
    "    \"\"\"\n",
    "    n = Phi.shape[1] # signal length.\n",
    "    T0 = list(T0)\n",
    "    x0 = np.zeros(n)\n",
    "    # Init.\n",
    "    q = np.ones(n) # q=(q1,...,qn)\n",
    "    q[T0] = tau\n",
    "    # Q = np.diag(q)\n",
    "        # Inverse weight matrix. Not used so as to accelerate.\n",
    "    x0 = (q * Phi).T.dot(conjGrad(Phi.dot((q * Phi).T),y)) # Weight by row.\n",
    "        # Cost:O((m^2*N^2)^3)=poly(m,N).\n",
    "\n",
    "    for t in range(maxIter):\n",
    "        q = np.abs(x0)**(2-p)\n",
    "        q[T0] *= tau\n",
    "        q += mu\n",
    "        x1 = (q * Phi).T.dot(conjGrad(Phi.dot((q*Phi).T),y))\n",
    "        dx = x1 - x0\n",
    "        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2)) \n",
    "        if showChangeRate:\n",
    "            print('Iter:',t,'ChangeRate:',changeRate) # Log.\n",
    "        if changeRate < np.sqrt(mu)/100:\n",
    "            if mu <= eps:\n",
    "                iter = t\n",
    "                break\n",
    "            else:\n",
    "                mu /= 10\n",
    "        x0 = x1\n",
    "    else: # Reach maxIter.\n",
    "        iter = maxIter-1\n",
    "        if showIfMaxIter:\n",
    "            print('Reach maxIter:',maxIter)\n",
    "    \n",
    "    if returnIter:\n",
    "        return (x1,iter)\n",
    "    else:\n",
    "        return x1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -1 测试信号生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rademacher(1,-1,Prob=0.5) on support.\n",
    "def randSparseSignal(n=2000,s=50,size=10000,returnSupports=False,allowLowerSparsity=False):\n",
    "    \"\"\"\n",
    "    Generate `size` number of signals of dimension `n` and sparsity `s`.\n",
    "    Aranged by columns.\n",
    "\n",
    "    If `returnSupports`=`True` then also return Supports of Signals aranged by columns,\n",
    "    repetitions might be included.\n",
    "    \"\"\"\n",
    "    size = int(size) # 转化形如`1e5`的输入.\n",
    "    V =  np.zeros((n,size),order='F',dtype=np.float32)\n",
    "    Supps = np.array([np.random.choice(range(n),s,replace=allowLowerSparsity) for _ in range(size)])\n",
    "        # 随机抽取支集, 存为每一行.\n",
    "    Entries = np.array(\n",
    "        [np.random.binomial(1,0.5,s).astype(np.float32)*2-1 for _ in range(size)])\n",
    "        # 随机赋予支集项的值, 存为每一行.\n",
    "    for j in range(size):\n",
    "        V[Supps[j],j] = Entries[j]\n",
    "    if returnSupports==True:\n",
    "        return dict(\n",
    "            Signals = V,\n",
    "            Supports = Supps.T\n",
    "        )\n",
    "    else:\n",
    "        return V"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -2|Exec! 数值测试\n",
    "建议用直接代码写出, 不封装."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate A, X.\n",
    "np.random.seed(42)\n",
    "A = randSampMat(2000,5000)\n",
    "XX = randSparseSignal(n=5000,s=50,size=20,returnSupports=True)\n",
    "X, Supps = XX['Signals']*10,XX['Supports']\n",
    "del XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max singular value: 1.1690437\n",
      "Min singular value: 0.8305824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1694176197052002"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mixed test. 需要的模拟次数可以远小于monteCarlo方法, 准确度也更大.\n",
    "RIPtest(A,50).mixedMethod(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.dot(A,X[:,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0 ChangeRate: 0.6197886925791511\n",
      "Iter: 1 ChangeRate: 0.22045252462258366\n",
      "Iter: 2 ChangeRate: 0.04946520524623124\n",
      "Iter: 3 ChangeRate: 0.009713478300626037\n",
      "Iter: 4 ChangeRate: 0.001895827564595032\n",
      "Iter: 5 ChangeRate: 0.00038607350471120736\n",
      "Iter: 6 ChangeRate: 8.361807091803353e-05\n",
      "Iter: 7 ChangeRate: 0.00019605486713606562\n",
      "Iter: 8 ChangeRate: 3.65230863606721e-05\n",
      "Iter: 9 ChangeRate: 2.5401381183906786e-05\n",
      "Iter: 10 ChangeRate: 6.615840089249745e-06\n",
      "Iter: 11 ChangeRate: 1.3619384465456692e-06\n",
      "4.0018846956872314e-05\n"
     ]
    }
   ],
   "source": [
    "# IRLSPKS\n",
    "x = IRLSPKS(Y[:,0],A,showIfMaxIter=True,showChangeRate=True)\n",
    "err = np.linalg.norm(x - X[:,0])\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CosampPKS\n",
    "ErrCosampPKS = []\n",
    "for j in range(Y.shape[1]):\n",
    "    x = CosampPKS(Y[:,j],A,50,maxIter=100,showIfMaxIter=True)\n",
    "    #看看误差.\n",
    "    err = np.linalg.norm(x - X[:,j])\n",
    "    ErrCosampPKS.append(err)\n",
    "    print(j,'Err:',err)\n",
    "else:\n",
    "    print('Mean Err:',np.mean(ErrCosampPKS))\n",
    "\n",
    "# IHTPKS\n",
    "ErrIHTPKS = []\n",
    "for j in range(Y.shape[1]):\n",
    "    x = IHTPKS(Y[:,j],A,50,maxIter=100,showIfMaxIter=True)\n",
    "    #看看误差.\n",
    "    err = np.linalg.norm(x - X[:,j])\n",
    "    ErrIHTPKS.append(err)\n",
    "    print(j,'Err:',err)\n",
    "else:\n",
    "    print('Mean Err:',np.mean(ErrIHTPKS))\n",
    "\n",
    "# OMPPKS\n",
    "# ErrOMPPKS = []\n",
    "# for j in range(Y.shape[1]):\n",
    "#     x = OMPPKS(Y[:,j],A,maxIter=100,showIfMaxIter=True)\n",
    "#     #看看误差.\n",
    "#     err = np.linalg.norm(x - X[:,j])\n",
    "#     ErrOMPPKS.append(err)\n",
    "#     print(j,'Err:',err)\n",
    "# else:\n",
    "#     print('Mean Err:',np.mean(ErrOMPPKS))\n",
    "\n",
    "plt.plot(ErrCosampPKS,ls='-.',label='cosamp')\n",
    "plt.axhline(np.mean(ErrCosampPKS),ls=':',label='mean cosamp')\n",
    "plt.plot(ErrIHTPKS,ls='--',label='iht')\n",
    "plt.axhline(np.mean(ErrIHTPKS),ls='-',label='mean iht')\n",
    "# plt.plot(ErrOMPPKS,label='omp')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 待改20230402\n",
    "# def test(Y,X,s,times=1000, func=IHTPKS, priorSuppRatio=0.2, SuppsReal=None, **kwargs):\n",
    "#     \"\"\"\n",
    "#     Run `times` times of `func` function\n",
    "#         given `Y`=[y1,...,yt], `X`=[x1,...,xt],\n",
    "#         use `priorSuppRatio`(from 0 to 1) instead of `T0`,\n",
    "#         `SuppsReal`: aranged by cols, if `None` then supps(X)(`s` needed),\n",
    "#         and `**kwargs` as other keyword arguments.\n",
    "    \n",
    "#     Return the results in an array.\n",
    "#     \"\"\"\n",
    "#     Results = []\n",
    "#     if SuppsReal is None:\n",
    "#         SuppsReal = np.zeros((s,X.shape[1])).astype('int')\n",
    "#         for j in range(X.shape[1]):\n",
    "#             SuppsReal[:,j] = np.argsort(np.abs(X[:,j]))[:-(s+1):-1] #兼容compressible signal.\n",
    "\n",
    "#     for t in range(times):\n",
    "#         T0 = np.random.choice(SuppsReal[:,t],int(round(s*priorSuppRatio,0)),replace=False)\n",
    "#         Results.append(func(y=Y[:,t],xReal=X[:,t],T0=T0,s=s,**kwargs))\n",
    "#     return Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -99|Exec! Debug area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4],\n",
       "       [3, 8]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2])*(np.array([[1,2],[3,4]]).T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([]).dot([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3][:-2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list({1,3,2,4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{1,2} | {3,2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([1,2,3,0,0,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - np.isclose(a+1e-12,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelorThesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fa5ea0a09a8cd9d0aa4e6bbb526a74c2e7a420b3d09cd1311bf211743dd137b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
