{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "## 20230401\n",
    "建议不要过度封装. 每个算法尽量展开写出.另外不要过度输出,可以只输出信号估计,而误差等可以不输出,而是改为在别的地方重新计算.|尝试加入haltingRule=('rIterErr',eps), 但不会以这种封装的方式, 而是针对个别算法.|以后要测试算法性能,考虑收敛时(因此要用'rIterErr'停机判定)取得的误差最小值,以及达到收敛需要的迭代次数.总的来看,'rIterErr'可能是比'rSampErr'更好的停机判据.\n",
    "## 20230402\n",
    "大改代码. 把算法统一到各自的功能中,去掉多余的参数,例如先知信号等.将停机法则统一为相对更新率收敛至`eps=1e-6`.由于要比较迭代次数,可以设置可选输出`returnIter=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations as cb\n",
    "import cvxopt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 预备函数\n",
    "## 1.1 随机采样阵生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机采样阵生成\n",
    "def randSampMat(m,N):\n",
    "    \"\"\"\n",
    "    Return m*N sampling matrix.\n",
    "    Use type `np.float32`.\n",
    "    \"\"\"\n",
    "    #用高斯分布抽样, 列单位化.\n",
    "    A = np.random.randn(m,N).astype(np.float32)\n",
    "    for j in range(A.shape[1]):\n",
    "        A[:,j] = A[:,j] / np.sqrt(A[:,j].dot(A[:,j]))\n",
    "    return A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 共轭梯度法\n",
    "(Iterative) Conjugate gradient method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjGrad(A,b,x=\"0\",eps=1e-6,showChangeRate=False):\n",
    "    \"\"\"\n",
    "    迭代的共轭梯度法. 要求A实正定对称.\n",
    "    `x`:初始点.\n",
    "    收敛相对误差|Δx[t]|/|x[t-1]|被`eps`控制.\n",
    "    方法优点: 迭代至多进行k=len(b)次. A事先计算出,控制迭代次数,则复杂度O(k^2).\n",
    "    不吝啬迭代则O(k^3).\n",
    "    \"\"\"\n",
    "    k = A.shape[0] # 行/列数。\n",
    "    if x=='0':\n",
    "        x = np.zeros(k)\n",
    "    r = b - np.dot(A,x)\n",
    "    p = r\n",
    "    r2old = r.dot(r)\n",
    "    for i in range(k):\n",
    "        Ap = A.dot(p)\n",
    "        alpha = r2old / (p.dot(Ap))\n",
    "        xOld = x\n",
    "        x = x + alpha * p\n",
    "        r = r - alpha * Ap\n",
    "        r2new = r.dot(r)\n",
    "        changeRate = np.sqrt((x-xOld).dot(x-xOld)/(eps**2 + x.dot(x)))\n",
    "            #相对迭代误差(改进率).\n",
    "        if showChangeRate:\n",
    "            print('Iter',i,':',changeRate)\n",
    "        if changeRate < eps:\n",
    "            break\n",
    "        p = r + (r2new/r2old)*p\n",
    "        r2old = r2new\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 限制等距常数估计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIP测试.\n",
    "class RIPtest:\n",
    "    def __init__(self,A,s):\n",
    "        \"\"\"\n",
    "        Return possible delta_s given matrix `A` and sparsity `s`.\n",
    "\n",
    "        Contain 2 methods:\n",
    "            `RIPtest(A,s).monteCarlo(nVec,show)`: Monte Carlo method;\n",
    "            `RIPtest(A,s).singularValue()`: singularValue method.\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        self.s = s\n",
    "    #         \n",
    "    # \n",
    "    # \n",
    "    #                 \n",
    "    # Monte-Carlo method.\n",
    "    def monteCarlo(self, nVec=1e5, show=True): # 这是一个对象方法.\n",
    "        # def fun() 是类方法; def fun(self) 是对象方法.\n",
    "        \"\"\"\n",
    "        Return possible delta_s given matrix `A` and sparsity `s`. \n",
    "        `nVec`: Number of vectors to test. \n",
    "        `show`: Whether to draw the distribution of amplifications.\n",
    "\n",
    "        Running time:\n",
    "            O(nVec=10000,N=10000,m=400)~70sec;\n",
    "            \n",
    "            O(nVec=5000,N=5000,m=200)~10sec;\n",
    "\n",
    "            O(nVec=100000,N=200,m=50)~3sec.\n",
    "        \"\"\"\n",
    "        \n",
    "        N = self.A.shape[1]\n",
    "        nVec = int(nVec) # 转化形如`1e5`的输入.\n",
    "        V =  np.zeros((N,nVec),order='F',dtype=np.float32) # 由多个s-稀疏的列向量组成. \n",
    "        Supps = np.array([np.random.choice(range(N),self.s,replace=False) for i in range(nVec)])\n",
    "            # 随机抽取支集, 存为每一行.\n",
    "        Entries = np.array([np.random.randn(self.s).astype(np.float32) for i in range(nVec)])\n",
    "            # 随机赋予支集项的值, 存为每一行. 未正规化.\n",
    "        for j in range(nVec):\n",
    "            # supp = Supps[j]\n",
    "            # entries = Entries[j]\n",
    "            V[Supps[j],j] = Entries[j]/np.linalg.norm(Entries[j])\n",
    "        V = np.dot(self.A,V)\n",
    "            # 象.\n",
    "        Amplifications = np.array(list(map(lambda v:np.linalg.norm(v), np.transpose(V))))\n",
    "        ampMax = np.max(Amplifications); delta1 = ampMax-1\n",
    "        ampMin = np.min(Amplifications); delta2 = 1-ampMin\n",
    "        delta = max(delta1,delta2)\n",
    "\n",
    "        if show==True:\n",
    "        # 用Gaussian近似检测delta估计是否超出3-sigma,若是,则认为delta即使再估计也不会显著增加,基本准确.\n",
    "            var = np.var(Amplifications)\n",
    "            mean = np.mean(Amplifications)\n",
    "            threeSigma = 3*np.sqrt(var)\n",
    "            ThreeSigmaPoints = [mean - threeSigma, mean + threeSigma]\n",
    "            Xnorm = np.linspace(ThreeSigmaPoints[0],ThreeSigmaPoints[1],100)\n",
    "            Ynorm = stats.norm.pdf((Xnorm-mean)/np.sqrt(var))/np.sqrt(var)\n",
    "\n",
    "            plt.hist(Amplifications,bins=100,density=True,label='Amplifications')\n",
    "            plt.plot(Xnorm,Ynorm,'r:',label='Gaussian Reference')\n",
    "            plt.axvline(ThreeSigmaPoints[0],linestyle='-.',color='g',label='-3 sigma')\n",
    "            plt.axvline(ThreeSigmaPoints[1],linestyle='--',color='m',label='+3 sigma')\n",
    "            plt.xlabel('Amp.')\n",
    "            plt.ylabel('Density')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            print(\"3-sigma points: [1 - {:}, 1 + {:}]\".format(1-ThreeSigmaPoints[0],ThreeSigmaPoints[1]-1))\n",
    "            \n",
    "            if delta==delta1:\n",
    "                side = 'Right'\n",
    "            else:\n",
    "                side = 'Left'\n",
    "            print(\"Side:\",side)\n",
    "        return delta\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    # SingularValue method.\n",
    "    def singularValue(self, SAFECODE, showSingularValues=True, mode='memory-saving'):\n",
    "        \"\"\"\n",
    "        有内存泄漏危险, 勿用!\n",
    "\n",
    "        确认使用时输入参数`SAFECODE=CONFIRM`.\n",
    "\n",
    "        Return delta_s.\n",
    "\n",
    "        `showSingularValues`: Whether to show the two max&min singularValues of all submatrices.\n",
    "        \n",
    "        Running time:\n",
    "            `mode='memory-saving'`: O(N=200,m=20,s=3)~30sec; O(N=2000,m=20,s=2)~39sec; O(N=2000,m=20,s=3)~ >5min.\n",
    "            \n",
    "            `mode='fast'`: O(N=200,m=20,s=3)~23sec; O(N=2000,m=20,s=2)~27sec; O(N=2000,m=20,s=3)~ >2min(MemoryError).\n",
    "        \n",
    "        建议:\n",
    "            1, 采用分布式计算, 因为耗时关于s指数级增长;\n",
    "            \n",
    "            2, 改用Monte-Carlo方法, 其估计概率已足够大;\n",
    "            \n",
    "            3, `fast`模式对于稍大矩阵几乎不能用, 基本上会报错`MemoryError`.\n",
    "        \"\"\"\n",
    "\n",
    "        if SAFECODE!='CONFIRM':\n",
    "            print('Not safe!')\n",
    "            return\n",
    "        \n",
    "        N = self.A.shape[1]\n",
    "\n",
    "        # 以时间换空间: 使用s个指针Pointers, 列举指针组合.\n",
    "        if mode=='memory-saving':\n",
    "            PtrCombinations = cb(range(N),self.s)\n",
    "            maxSv, minSv = 1, 1\n",
    "            for ptr in PtrCombinations:\n",
    "                ptr = list(ptr)\n",
    "                Svs = np.linalg.svd(self.A[:,ptr])[1] \n",
    "                    # `Svs` for 'Singular Values'.\n",
    "                    # Only accept float32+ type.\n",
    "                maxSv = max(np.max(Svs),maxSv)\n",
    "                minSv = min(np.min(Svs),minSv)\n",
    "\n",
    "        # ↑↓ 以空间换时间.\n",
    "        elif mode=='fast':\n",
    "            Submatrices = np.array(list(cb(self.A.transpose(),self.s)))\n",
    "\n",
    "            # Svs = np.array(list(map(np.linalg.svd,\n",
    "            #           Submatrices))).reshape(1,-1)[0]\n",
    "            # ↑↓ Equivalent.\n",
    "            Svs = np.linalg.svd(Submatrices)[1].reshape(1,-1)[0]\n",
    "\n",
    "            maxSv = max(Svs)\n",
    "            minSv = min(Svs)\n",
    "\n",
    "        delta = max(maxSv - 1, 1 - minSv)\n",
    "        if showSingularValues==True:\n",
    "            print('Max singular value:', maxSv)\n",
    "            print('Min singular value:', minSv)\n",
    "        return delta\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    # A mixed version.\n",
    "    def mixedMethod(self, times=10000, showSingularValues=True):\n",
    "        \"\"\"\n",
    "        A better and safe mixed version of Monte-Carlo & SingularValue.\n",
    "        \"\"\"\n",
    "        N = self.A.shape[1]\n",
    "        maxSv, minSv = 1, 1\n",
    "        for t in range(times):\n",
    "            comb = np.random.choice(range(N),self.s,replace=False)\n",
    "            submatrix = self.A[:,comb].astype(np.float32)\n",
    "            Svs = np.linalg.eigvals(np.dot(submatrix.transpose(),submatrix))\n",
    "                # `Svs` for 'Singular Values'.\n",
    "                # Only accept float32+ type.\n",
    "            maxSv = max(np.sqrt(np.max(Svs)),maxSv)\n",
    "            minSv = min(np.sqrt(np.min(Svs)),minSv)\n",
    "\n",
    "        delta = max(maxSv - 1, 1 - minSv)\n",
    "        if showSingularValues==True:\n",
    "            print('Max singular value:', maxSv)\n",
    "            print('Min singular value:', minSv)\n",
    "        return delta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 硬阈值函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 硬阈值函数\n",
    "def hardThreshold(x,s,T0=[]):\n",
    "    \"\"\"\n",
    "    Return x with its largest s-k entries and k entries indexed in T0, the rest set to 0.\n",
    "    \"\"\"\n",
    "    N = len(x)\n",
    "    k = len(T0)\n",
    "    comparingVec = x.copy()\n",
    "    comparingVec[T0]=0 #去掉支集项以寻找剩余元素的s-k个最大值.\n",
    "    delta = np.abs(comparingVec).argsort()[:-(s-k+1):-1] #返回s-k个绝对最大值的索引.\n",
    "    supp = np.append(T0, delta).astype('int64')\n",
    "    new = np.zeros(N)\n",
    "    new[supp]=x[supp]\n",
    "\n",
    "    return new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Expired). errAnalyze()\n",
    "可以作以后误差分析的参考."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errAnalyze(xReal,suppReal,x1,N,s,showPrecisionAndRecall,iterCount,eps,y,err,yNorm):\n",
    "    \"\"\"\n",
    "    errAnalyze(xReal,suppReal,x1,N,s,showPrecisionAndRecall,iterCount,eps,y,err,yNorm)\n",
    "        -> dict(\n",
    "            estimate,iterCount,eps,y,errY,relativeErrY,confusion\n",
    "        )\n",
    "    \"\"\"\n",
    "    if not (xReal is None):\n",
    "        if suppReal is None:\n",
    "            suppReal = np.argsort(np.abs(xReal))[:-(s+1):-1] #兼容compressible signal.\n",
    "        \n",
    "        # Compute confusion matrix.\n",
    "        nPositive = np.sum(1-np.isclose(x1,0))\n",
    "        nTruePositive = np.sum(1-np.isclose(x1[suppReal],0))\n",
    "        nFalsePositive = nPositive - nTruePositive\n",
    "        nNegative = N - nPositive\n",
    "        nFalseNegative = np.sum(np.isclose(x1[suppReal],0))\n",
    "        nTrueNegative = nNegative - nFalseNegative\n",
    "\n",
    "        confusion = pd.DataFrame(np.array([\n",
    "            [nTruePositive,nTrueNegative],\n",
    "            [nFalsePositive,nFalseNegative]\n",
    "        ]), columns=['positive','negative'],index=['true','false'])\n",
    "        if showPrecisionAndRecall == True:\n",
    "            print('precision:',nTruePositive/(nTruePositive + nFalsePositive))\n",
    "            print('recall:',nTruePositive/(nTruePositive + nFalseNegative))\n",
    "\n",
    "    else:\n",
    "        confusion = None\n",
    "    \n",
    "    return dict(\n",
    "        estimate=x1,\n",
    "        iterCount=iterCount,\n",
    "        eps=eps,\n",
    "        y=y,\n",
    "        errY=err,\n",
    "        relativeErrY=err/yNorm,\n",
    "        confusion=confusion\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 主要算法\n",
    "## 2.1 IHT-PKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IHT-PKS\n",
    "def IHTPKS(y:np.ndarray, Phi:np.ndarray, s:int, x0='0', T0=[], mu=1,\n",
    "           maxIter:int=100,eps=1e-6,\n",
    "           returnIter=False,\n",
    "           showIfMaxIter=False, showChangeRate=False):\n",
    "    \"\"\"\n",
    "    `mu`:Learning rate.\\n\n",
    "    Return signal estimate.\\n\n",
    "    If `returnIter`, return tuple(signalEsti,iter).\n",
    "    \"\"\"\n",
    "    n = Phi.shape[1] # signal length.\n",
    "    if x0=='0':\n",
    "        x0 = np.zeros(n)\n",
    "\n",
    "    for t in range(maxIter):\n",
    "        p = x0 + mu * Phi.T.dot(y - Phi.dot(x0)) # proxy.\n",
    "        x1 = hardThreshold(p,s,T0)\n",
    "        dx = x1-x0\n",
    "        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2)) \n",
    "        if showChangeRate:\n",
    "            print('Iter:',t,'ChangeRate:',changeRate)\n",
    "        if changeRate<eps:\n",
    "            iter = t\n",
    "            break\n",
    "        else:\n",
    "            x0 = x1\n",
    "    else: # Reach maxIter.\n",
    "        iter = maxIter-1\n",
    "        if showIfMaxIter:\n",
    "            print('Reach maxIter:',maxIter)\n",
    "    \n",
    "    if returnIter:\n",
    "        return (x1,iter)\n",
    "    else:\n",
    "        return x1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 OMP-PKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OMP_PKS(y, Phi:np.ndarray, x0='0', T0=[],\n",
    "           maxIter:int=100, eps=1e-6,\n",
    "           returnIter=False,\n",
    "           showIfMaxIter=False, showChangeRate=False):\n",
    "    \"\"\"\n",
    "    Does not require sparsity 's'.\n",
    "    \"\"\"\n",
    "    # Init.\n",
    "    n = Phi.shape[1]\n",
    "    if x0=='0':\n",
    "        x0 = np.zeros(n)\n",
    "    supp = list(T0) # PKS.\n",
    "\n",
    "    # Iteration.\n",
    "    for t in range(maxIter):\n",
    "        p = Phi.T.dot(y - Phi.dot(x0)) # proxy.\n",
    "        j = np.argmax(np.abs(p))\n",
    "        if j not in supp:\n",
    "            supp.append(j)\n",
    "        x1 = np.zeros(n)\n",
    "        # Use conjGrad to solve lstsq problem.\n",
    "            # Note here the problem is |Phi.T.dot(Phi).dot(x)-Phi.T.dot(y)|->0.\n",
    "        x1[supp] = conjGrad(Phi[:,supp].T.dot(Phi[:,supp]),Phi[:,supp].T.dot(y))\n",
    "\n",
    "        dx = x1 - x0\n",
    "        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2)) \n",
    "        if changeRate < eps:\n",
    "            iter = t\n",
    "            break\n",
    "        else:\n",
    "            x0 = x1\n",
    "    else: # maxIter.\n",
    "        iter = maxIter-1\n",
    "        if showIfMaxIter:\n",
    "            print('Reach maxIter:',maxIter)\n",
    "\n",
    "    if returnIter:\n",
    "        return (x1,iter)\n",
    "    else:\n",
    "        return x1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 CoSaMP-PKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -1 测试信号生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rademacher(1,-1,Prob=0.5) on support.\n",
    "def randSparseSignal(N=2000,s=50,size=10000,returnSupports=False,allowLowerSparsity=False):\n",
    "    \"\"\"\n",
    "    Generate `size` number of signals of dimension `N` and sparsity `s`.\n",
    "    Aranged by columns.\n",
    "\n",
    "    If `returnSupports`=`True` then also return Supports of Signals aranged by columns,\n",
    "    repetitions might be included.\n",
    "    \"\"\"\n",
    "    size = int(size) # 转化形如`1e5`的输入.\n",
    "    V =  np.zeros((N,size),order='F',dtype=np.float32)\n",
    "    Supps = np.array([np.random.choice(range(N),s,replace=allowLowerSparsity) for _ in range(size)])\n",
    "        # 随机抽取支集, 存为每一行.\n",
    "    Entries = np.array(\n",
    "        [np.random.binomial(1,0.5,s).astype(np.float32)*2-1 for _ in range(size)])\n",
    "        # 随机赋予支集项的值, 存为每一行.\n",
    "    for j in range(size):\n",
    "        V[Supps[j],j] = Entries[j]\n",
    "    if returnSupports==True:\n",
    "        return dict(\n",
    "            Signals = V,\n",
    "            Supports = Supps.T\n",
    "        )\n",
    "    else:\n",
    "        return V"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -2 数值测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate A, X.\n",
    "np.random.seed(42)\n",
    "A = randSampMat(400,1000)\n",
    "XX = randSparseSignal(N=1000,s=50,size=1000,returnSupports=True)\n",
    "X, Supps = XX['Signals']*10,XX['Supports']\n",
    "del XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max singular value: 1.4861118\n",
      "Min singular value: 0.5269956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48611176013946533"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mixed test. 需要的模拟次数可以远小于monteCarlo方法, 准确度也更大.\n",
    "RIPtest(A,80).mixedMethod(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 待改20230402\n",
    "def test(Y,X,s,times=1000, func=IHTPKS, priorSuppRatio=0.2, SuppsReal=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Run `times` times of `func` function\n",
    "        given `Y`=[y1,...,yt], `X`=[x1,...,xt],\n",
    "        use `priorSuppRatio`(from 0 to 1) instead of `T0`,\n",
    "        `SuppsReal`: aranged by cols, if `None` then supps(X)(`s` needed),\n",
    "        and `**kwargs` as other keyword arguments.\n",
    "    \n",
    "    Return the results in an array.\n",
    "    \"\"\"\n",
    "    Results = []\n",
    "    if SuppsReal is None:\n",
    "        SuppsReal = np.zeros((s,X.shape[1])).astype('int')\n",
    "        for j in range(X.shape[1]):\n",
    "            SuppsReal[:,j] = np.argsort(np.abs(X[:,j]))[:-(s+1):-1] #兼容compressible signal.\n",
    "\n",
    "    for t in range(times):\n",
    "        T0 = np.random.choice(SuppsReal[:,t],int(round(s*priorSuppRatio,0)),replace=False)\n",
    "        Results.append(func(y=Y[:,t],xReal=X[:,t],T0=T0,s=s,**kwargs))\n",
    "    return Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.dot(A,X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试cvxopt\n",
    "# mod-(reg)-BPDN可以转化为一个二次规划问题, 用qp()解决.\n",
    "# cvxopt.solvers.qp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = OMP_PKS(Y[:,0],A,showIfMaxIter=True,showChangeRate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3630603162433204e-05"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#看看误差.\n",
    "np.linalg.norm(x - X[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelorThesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fa5ea0a09a8cd9d0aa4e6bbb526a74c2e7a420b3d09cd1311bf211743dd137b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
