{"cells":[{"cell_type":"markdown","source":"# Log\n## 20230331\nmod-(reg)-BPDN可以转化为一个二次规划问题, 用qp()解决.\n`cvxopt.solvers.qp()`\n(20230407) 可以进一步转化为线性规划, 用lp()解决.\n## 20230401\n建议不要过度封装. 每个算法尽量展开写出.另外不要过度输出,可以只输出信号估计,而误差等可以不输出,而是改为在别的地方重新计算.|尝试加入haltingRule=('rIterErr',eps), 但不会以这种封装的方式, 而是针对个别算法.|以后要测试算法性能,考虑收敛时(因此要用'rIterErr'停机判定)取得的误差最小值,以及达到收敛需要的迭代次数.总的来看,'rIterErr'可能是比'rSampErr'更好的停机判据.\n## 20230402\n大改代码. 把算法统一到各自的功能中,去掉多余的参数,例如先知信号等.将停机法则统一为相对更新率收敛至`eps=1e-6`.由于要比较迭代次数,可以设置可选输出`returnIter=True`.\n题目含有'Exec!'的为直接可执行代码区域,注意绕开.\n## 20230404\n把所有向量维数统一为`n`,之后可能的时间序列长度记为`N`.\n## 20230405\n写完IRLSPKS. 算法性能比较可以从时间、先验贡献、RIP、重建误差、准确率和召回率、广义准确率和召回率(s-稀疏化后)等, 待补充.","metadata":{"cell_id":"3b9b35f3e1ca444eb6b64c717f63c7a8","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nfrom itertools import combinations as cb\nimport cvxopt","metadata":{"cell_id":"1c47ca66995545bf959e8ab5dc14c3f1","source_hash":"d3bfa7a2","execution_start":1680842284642,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# 1 预备函数\n## 1.1 随机采样阵生成","metadata":{"cell_id":"fc6acc58a6fa424c953a52d0e3e0778b","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# 随机采样阵生成\ndef randSampMat(m,n):\n    \"\"\"\n    Return m*n sampling matrix.\n    Use type `np.float32`.\n    \"\"\"\n    #用高斯分布抽样, 列单位化.\n    A = np.random.randn(m,n).astype(np.float32)\n    for j in range(A.shape[1]):\n        A[:,j] = A[:,j] / np.sqrt(A[:,j].dot(A[:,j]))\n    return A","metadata":{"cell_id":"27cb3073ea744dd89b069251235fff28","source_hash":"d73ce22c","execution_start":1680842284641,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## 1.2 共轭梯度法\n(Iterative) Conjugate gradient method.","metadata":{"cell_id":"0a91bad99a6a41c987a283e3614a06a3","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"def conjGrad(A,b,maxIter=-1,x=\"0\",eps=1e-6,showChangeRate=False):\n    \"\"\"\n    迭代的共轭梯度法. 要求A实正定对称.\n    `x`:初始点.\n    收敛相对误差|Δx[t]|/|x[t-1]|被`eps`控制.\n    方法优点: 迭代至多进行k=len(b)次. A事先计算出,控制迭代次数,则复杂度O(k^2).\n    不吝啬迭代则O(k^3).\n    \"\"\"\n    k = A.shape[0] # 行/列数。\n    if maxIter==-1:\n        maxIter = k\n    if x=='0':\n        x = np.zeros(k)\n    r = b - np.dot(A,x)\n    p = r\n    r2old = r.dot(r)\n    for i in range(maxIter):\n        Ap = A.dot(p)\n        alpha = r2old / (p.dot(Ap))\n        xOld = x\n        x = x + alpha * p\n        r = r - alpha * Ap\n        r2new = r.dot(r)\n        changeRate = np.sqrt((x-xOld).dot(x-xOld)/(eps**2 + x.dot(x)))\n            #相对迭代误差(改进率).\n        if showChangeRate:\n            print('Iter',i,':',changeRate)\n        if changeRate < eps:\n            break\n        p = r + (r2new/r2old)*p\n        r2old = r2new\n    return x","metadata":{"cell_id":"fe69417ba17f4fb7ac2268af138529db","source_hash":"bcf419df","execution_start":1680842284642,"execution_millis":5,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## 1.3 限制等距常数估计","metadata":{"cell_id":"9313c0206f4248ddb55067b08c384876","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# RIP测试.\nclass RIPtest:\n    def __init__(self,A,s):\n        \"\"\"\n        Return possible delta_s given matrix `A` and sparsity `s`.\n\n        Contain 2 methods:\n            `RIPtest(A,s).monteCarlo(nVec,show)`: Monte Carlo method;\n            `RIPtest(A,s).singularValue()`: singularValue method.\n        \"\"\"\n        self.A = A\n        self.s = s\n    #         \n    # \n    # \n    #                 \n    # Monte-Carlo method.\n    def monteCarlo(self, nVec=1e5, show=True): # 这是一个对象方法.\n        \"\"\"\n        Return possible delta_s given matrix `A` and sparsity `s`. \\n\n        `nVec`: Number of vectors to test. \\n\n        `show`: Whether to draw the distribution of amplifications. \\n\n        Running time: \\n\n            O(nVec=10000,n=10000,m=400)~70sec; \\n\n            O(nVec=5000,n=5000,m=200)~10sec; \\n\n            O(nVec=100000,n=200,m=50)~3sec.\n        \"\"\"\n        n = self.A.shape[1]\n        nVec = int(nVec) # 转化形如`1e5`的输入.\n        V =  np.zeros((n,nVec),order='F',dtype=np.float32) # 由多个s-稀疏的列向量组成. \n        Supps = np.array([np.random.choice(range(n),self.s,replace=False) for i in range(nVec)])\n            # 随机抽取支集, 存为每一行.\n        Entries = np.array([np.random.randn(self.s).astype(np.float32) for i in range(nVec)])\n            # 随机赋予支集项的值, 存为每一行. 未正规化.\n        for j in range(nVec):\n            # supp = Supps[j]\n            # entries = Entries[j]\n            V[Supps[j],j] = Entries[j]/np.linalg.norm(Entries[j])\n        V = np.dot(self.A,V)\n            # 象.\n        Amplifications = np.array(list(map(lambda v:np.linalg.norm(v), np.transpose(V))))\n        ampMax = np.max(Amplifications); delta1 = ampMax-1\n        ampMin = np.min(Amplifications); delta2 = 1-ampMin\n        delta = max(delta1,delta2)\n\n        if show==True:\n        # 用Gaussian近似检测delta估计是否超出3-sigma,若是,则认为delta即使再估计也不会显著增加,基本准确.\n            var = np.var(Amplifications)\n            mean = np.mean(Amplifications)\n            threeSigma = 3*np.sqrt(var)\n            ThreeSigmaPoints = [mean - threeSigma, mean + threeSigma]\n            Xnorm = np.linspace(ThreeSigmaPoints[0],ThreeSigmaPoints[1],100)\n            Ynorm = stats.norm.pdf((Xnorm-mean)/np.sqrt(var))/np.sqrt(var)\n\n            plt.hist(Amplifications,bins=100,density=True,label='Amplifications')\n            plt.plot(Xnorm,Ynorm,'r:',label='Gaussian Reference')\n            plt.axvline(ThreeSigmaPoints[0],linestyle='-.',color='g',label='-3 sigma')\n            plt.axvline(ThreeSigmaPoints[1],linestyle='--',color='m',label='+3 sigma')\n            plt.xlabel('Amp.')\n            plt.ylabel('Density')\n            plt.legend()\n            plt.show()\n            print(\"3-sigma points: [1 - {:}, 1 + {:}]\".format(1-ThreeSigmaPoints[0],ThreeSigmaPoints[1]-1))\n            \n            if delta==delta1:\n                side = 'Right'\n            else:\n                side = 'Left'\n            print(\"Side:\",side)\n        return delta\n    #\n    #\n    #\n    # SingularValue method.\n    def singularValue(self, SAFECODE, showSingularValues=True, mode='memory-saving'):\n        \"\"\"\n        有内存泄漏危险, 勿用! \\n\n        确认使用时输入参数`SAFECODE=CONFIRM`. \\n\n        Return delta_s. \\n\n        `showSingularValues`: Whether to show the two max&min singularValues of all submatrices. \\n\n        Running time: \\n\n            `mode='memory-saving'`: O(n=200,m=20,s=3)~30sec; O(n=2000,m=20,s=2)~39sec; O(n=2000,m=20,s=3)~ >5min. \\n\n            `mode='fast'`: O(n=200,m=20,s=3)~23sec; O(n=2000,m=20,s=2)~27sec; O(n=2000,m=20,s=3)~ >2min(MemoryError). \\n        \n        建议: \\n\n            1, 采用分布式计算, 因为耗时关于s指数级增长; \\n\n            2, 改用Monte-Carlo方法, 其估计概率已足够大; \\n\n            3, `fast`模式对于稍大矩阵几乎不能用, 基本上会报错`MemoryError`.\n        \"\"\"\n        if SAFECODE!='CONFIRM':\n            print('Not safe!')\n            return\n        n = self.A.shape[1]\n        # 以时间换空间: 使用s个指针Pointers, 列举指针组合.\n        if mode=='memory-saving':\n            PtrCombinations = cb(range(n),self.s)\n            maxSv, minSv = 1, 1\n            for ptr in PtrCombinations:\n                ptr = list(ptr)\n                Svs = np.sqrt(np.linalg.eigvals(self.A[:,ptr].T.dot(self.A[:,ptr]))) \n                    # `Svs` for 'Singular Values'.\n                    # Only accept float32+ type.\n                maxSv = max(np.max(Svs),maxSv)\n                minSv = min(np.min(Svs),minSv)\n        # 以空间换时间.\n        elif mode=='fast':\n            Submatrices = np.array(list(cb(self.A.transpose(),self.s)))\n            Svs = np.sqrt(np.linalg.eigvals(Submatrices.T.dot(Submatrices)))\n\n            maxSv = max(Svs)\n            minSv = min(Svs)\n\n        delta = max(maxSv - 1, 1 - minSv)\n        if showSingularValues==True:\n            print('Max singular value:', maxSv)\n            print('Min singular value:', minSv)\n        return delta\n    #\n    #\n    #\n    #\n    # A mixed version.\n    def mixedMethod(self, times=10000, showSingularValues=True):\n        \"\"\"\n        A better and safe mixed version of Monte-Carlo & SingularValue.\n        \"\"\"\n        n = self.A.shape[1]\n        maxSv, minSv = 1, 1\n        for t in range(times):\n            comb = np.random.choice(range(n),self.s,replace=False)\n            submatrix = self.A[:,comb].astype(np.float32)\n            Svs = np.linalg.eigvals(np.dot(submatrix.transpose(),submatrix))\n                # `Svs` for 'Singular Values'.\n                # Only accept float32+ type.\n            maxSv = max(np.sqrt(np.max(Svs)),maxSv)\n            minSv = min(np.sqrt(np.min(Svs)),minSv)\n\n        delta = max(maxSv - 1, 1 - minSv)\n        if showSingularValues==True:\n            print('Max singular value:', maxSv)\n            print('Min singular value:', minSv)\n        return delta","metadata":{"cell_id":"fe9f28032e374ea1afa51e947532dc6b","source_hash":"7f460242","execution_start":1680842284654,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## 1.4 硬阈值函数","metadata":{"cell_id":"c7811bf50b5e42798291fa8f66d967be","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# 硬阈值函数\ndef hardThreshold(x,s,T0=[]):\n    \"\"\"\n    Return x with its largest s-k entries and k entries indexed in T0, the rest set to 0.\n    \"\"\"\n    n = len(x)\n    k = len(T0)\n    comparingVec = x.copy()\n    comparingVec[T0]=0 #去掉支集项以寻找剩余元素的s-k个最大值.\n    delta = np.abs(comparingVec).argsort()[:-(s-k+1):-1] #返回s-k个绝对最大值的索引.\n    supp = np.append(T0, delta).astype('int64')\n    new = np.zeros(n)\n    new[supp]=x[supp]\n\n    return new","metadata":{"cell_id":"622bd9e2b33a4adbbe312626dbb84b31","source_hash":"29b32a7a","execution_start":1680842284670,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## 1.5 取支集","metadata":{"cell_id":"ba5a22fcb59640c38bcb835aa0d83063","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"def getSupp(x:np.ndarray,s:int=-1):\n    \"\"\"\n    Return supp(x_s) corresponding to from Largest to Smallest. \\n\n    If `s` left default, -1, then s=sum(x!=0).\n    \"\"\"\n    if s==-1:\n        s = sum(1 - np.isclose(x,0))\n    return np.abs(x).argsort()[:-s-1:-1]","metadata":{"cell_id":"2d3f1305a7d6423ca331c33249dea790","source_hash":"5d98cbe3","execution_start":1680842284670,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## (Deprecated). errAnalyze()\n可以作以后误差分析的参考.","metadata":{"cell_id":"d4f4f0eb09ba40a8be5dc2902263ddac","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# def errAnalyze(xReal,suppReal,x1,n,s,showPrecisionAndRecall,iterCount,eps,y,err,yNorm):\n#     \"\"\"\n#     errAnalyze(xReal,suppReal,x1,n,s,showPrecisionAndRecall,iterCount,eps,y,err,yNorm)\n#         -> dict(\n#             estimate,iterCount,eps,y,errY,relativeErrY,confusion\n#         )\n#     \"\"\"\n#     if not (xReal is None):\n#         if suppReal is None:\n#             suppReal = np.argsort(np.abs(xReal))[:-(s+1):-1] #兼容compressible signal.\n        \n#         # Compute confusion matrix.\n#         nPositive = np.sum(1-np.isclose(x1,0))\n#         nTruePositive = np.sum(1-np.isclose(x1[suppReal],0))\n#         nFalsePositive = nPositive - nTruePositive\n#         nNegative = n - nPositive\n#         nFalseNegative = np.sum(np.isclose(x1[suppReal],0))\n#         nTrueNegative = nNegative - nFalseNegative\n\n#         confusion = pd.DataFrame(np.array([\n#             [nTruePositive,nTrueNegative],\n#             [nFalsePositive,nFalseNegative]\n#         ]), columns=['positive','negative'],index=['true','false'])\n#         if showPrecisionAndRecall == True:\n#             print('precision:',nTruePositive/(nTruePositive + nFalsePositive))\n#             print('recall:',nTruePositive/(nTruePositive + nFalseNegative))\n\n#     else:\n#         confusion = None\n    \n#     return dict(\n#         estimate=x1,\n#         iterCount=iterCount,\n#         eps=eps,\n#         y=y,\n#         errY=err,\n#         relativeErrY=err/yNorm,\n#         confusion=confusion\n#     )","metadata":{"cell_id":"377741bc7232438ab4eb701bc7072379","source_hash":"b7cc97c3","execution_start":1680842284671,"execution_millis":18,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# 2 静态CS算法\n## 2.1 IHT-PKS","metadata":{"cell_id":"6df26145cc1940c09d6a818cce435c33","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# IHT-PKS\ndef IHTPKS(y:np.ndarray, Phi:np.ndarray, s:int, x0='0', T0=[], mu=1,\n           maxIter:int=100,eps=1e-6,\n           returnIter=False,\n           showIfMaxIter=False, showChangeRate=False):\n    \"\"\"\n    `mu`:Learning rate. \\n\n    Return signal estimate. \\n\n    If `returnIter`, return tuple(signalEsti,iter).\n    \"\"\"\n    n = Phi.shape[1] # signal length.\n    if x0=='0':\n        x0 = np.zeros(n)\n\n    for t in range(maxIter):\n        p = x0 + mu * Phi.T.dot(y - Phi.dot(x0)) # proxy.\n        x1 = hardThreshold(p,s,T0)\n        dx = x1-x0\n        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2)) \n        if showChangeRate:\n            print('Iter:',t,'ChangeRate:',changeRate) # Log.\n        if changeRate<eps:\n            iter = t\n            break\n        else:\n            x0 = x1\n    else: # Reach maxIter.\n        iter = maxIter-1\n        if showIfMaxIter:\n            print('Reach maxIter:',maxIter)\n    \n    if returnIter:\n        return (x1,iter)\n    else:\n        return x1","metadata":{"cell_id":"76bdeb6f09d74a6ca3a772beaac88533","source_hash":"52695bd6","execution_start":1680842284688,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## 2.2 OMP-PKS","metadata":{"cell_id":"07b2426e9f304490a5ea9cbb83c57d41","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"def OMPPKS(y, Phi:np.ndarray, x0='0', T0=[],\n           maxIter:int=100, eps=1e-6,\n           returnIter=False,\n           showIfMaxIter=False, showChangeRate=False):\n    \"\"\"\n    Does not require sparsity 's'.\n    \"\"\"\n    # Init.\n    n = Phi.shape[1]\n    if x0=='0':\n        x0 = np.zeros(n)\n    supp = list(T0) # PKS.\n\n    # Iteration.\n    for t in range(maxIter):\n        p = Phi.T.dot(y - Phi.dot(x0)) # proxy.\n        j = np.argmax(np.abs(p))\n        if j not in supp:\n            supp.append(j)\n        x1 = np.zeros(n)\n        # Use conjGrad to solve lstsq problem.\n            # Note here the problem is |Phi.T.dot(Phi).dot(x)-Phi.T.dot(y)|->0.\n        x1[supp] = conjGrad(Phi[:,supp].T.dot(Phi[:,supp]),Phi[:,supp].T.dot(y))\n\n        dx = x1 - x0\n        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2))\n        if showChangeRate:\n            print('Iter:',t,'ChangeRate:',changeRate) # Log.\n        if changeRate < eps:\n            iter = t\n            break\n        else:\n            x0 = x1\n    else: # maxIter.\n        iter = maxIter-1\n        if showIfMaxIter:\n            print('Reach maxIter:',maxIter)\n\n    if returnIter:\n        return (x1,iter)\n    else:\n        return x1","metadata":{"cell_id":"dd488dace18a49ab842ce7cbb8a378e2","source_hash":"e324a159","execution_start":1680842284688,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## 2.3 CoSaMP-PKS","metadata":{"cell_id":"a3e9463415da45afb8e4bb5cce596752","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# CosampPKS\ndef CosampPKS(y:np.ndarray, Phi:np.ndarray, s:int, T0=[],\n            conjGradIter = -1,\n            maxIter:int=100,eps=1e-6,\n            returnIter=False,\n            showIfMaxIter=False, showChangeRate=False):\n    \"\"\"\n    Return signal estimate. \\n\n    If `returnIter`, return tuple(signalEsti,iter).\n\n    If `conjGradIter` left default, -1, then it iterates enough times.\n    \"\"\"\n    n = Phi.shape[1] # signal length.\n    T0 = list(T0)\n    x0 = np.zeros(n)\n    if len(T0)>0: # A priori.\n        x0[T0] = conjGrad(Phi[:,T0].T.dot(Phi[:,T0]),Phi[:,T0].T.dot(y),conjGradIter)\n    r = y - Phi[:,T0].dot(x0[T0]) # 感知残差.\n    K = s - len(T0) # 剩余稀疏度.\n\n    for t in range(maxIter):\n        p = Phi.T.dot(r) # proxy.\n        Omega = getSupp(p,2*K) # 2K-supp of proxy.\n        Tm = list(set(Omega) | set(getSupp(x0))) # Supp merge.\n        b = np.zeros(n)\n        b[Tm] = conjGrad(Phi[:,Tm].T.dot(Phi[:,Tm]),Phi[:,Tm].T.dot(y),conjGradIter)\n            # Elaborative solution.\n        A = b.copy()\n        A[T0] = 0 # Auxiliary.\n        x1 = np.zeros(n)\n        supp = list(set(T0)|set(getSupp(A,K)))\n        x1[supp] = b[supp]\n        r = y - Phi.dot(x1) \n\n        dx = x1 - x0\n        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2)) \n        if showChangeRate:\n            print('Iter:',t,'ChangeRate:',changeRate) # Log.\n        if changeRate<eps:\n            iter = t\n            break\n        else:\n            x0 = x1\n    else: # Reach maxIter.\n        iter = maxIter-1\n        if showIfMaxIter:\n            print('Reach maxIter:',maxIter)\n    \n    if returnIter:\n        return (x1,iter)\n    else:\n        return x1","metadata":{"cell_id":"d52f5bd9dc4540699cffd8dad0c926d5","source_hash":"fce40208","execution_start":1680842284705,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## 2.4 RWLS-Sl0-PKS","metadata":{"cell_id":"f35166249bc44fdab189db0babb4c78e","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# RWLSSl0PKS.\ndef RWLSSl0PKS(y:np.ndarray, Phi:np.ndarray, T0=[],\n            lamb=1e-4, sigmaMin=1e-8,\n            conjGradIter=-1,\n            maxIter:int=100,eps=1e-6,\n            returnIter=False,\n            showIfMaxIter=False, showChangeRate=False):\n    \"\"\"\n    `lamb`: Recommend (noise^2)*sqrt(1.5*log(n)). \\n\n    Return signal estimate. \\n\n    If `returnIter`, return tuple:(signalEsti,iter). \\n\n    If `conjGradIter` left default, -1, then it iterates enough times.\n    \"\"\"\n    m,n = Phi.shape\n    T0 = list(T0)\n    x0 = np.zeros(n)\n    K = int(m/np.log(n/m)) # Very rough Sparsity estimate.\n    # Init.\n    w = np.ones(n) # We let w=inverse(w1,...,wn)\n    w[T0] = 100\n    x0 = (w * Phi).T.dot(conjGrad(Phi.dot((w * Phi).T)+lamb*np.identity(m),y)) # Weight by row.\n        # Cost:O((m^2*n^2)^3)=poly(m,n).\n\n    for t in range(maxIter):\n        sigma = max(sigmaMin,sorted(np.abs(x0))[-(K+1)])\n        w = (sigma + np.abs(x0))**2\n        w[T0] *= 100        \n        x1 = (w * Phi).T.dot(conjGrad(Phi.dot((w * Phi).T)+lamb*np.identity(m),y))\n\n        dx = x1 - x0\n        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2)) \n        if showChangeRate:\n            print('Iter:',t,'ChangeRate:',changeRate) # Log.\n        if changeRate < eps:\n            iter = t\n            break\n        x0 = x1\n    else: # Reach maxIter.\n        iter = maxIter-1\n        if showIfMaxIter:\n            print('Reach maxIter:',maxIter)\n    \n    if returnIter:\n        return (x1,iter)\n    else:\n        return x1","metadata":{"cell_id":"5c82f22a61bf4a8199ddcf86336dd166","source_hash":"43abda79","execution_start":1680842284705,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## 2.5 IRLS-PKS","metadata":{"cell_id":"f6fd683f47dd44e0b424fd4ecf98016a","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# IRLSPKS.\ndef IRLSPKS(y:np.ndarray, Phi:np.ndarray, T0=[],\n            p:int=1, mu=1e-3, tau=1e-3,\n            conjGradIter=-1,\n            maxIter:int=100,eps=1e-6,\n            returnIter=False,\n            showIfMaxIter=False, showChangeRate=False):\n    \"\"\"\n    `p`: Norm number, in (0,1]. \\n\n    `mu`: Normalizing param. `sqrt(mu)/100`'s Minimum is `eps`. \\n\n    `tau`: Short for tau^(2-p) in the paper. Weighting param. \\n\n    Return signal estimate. \\n\n    If `returnIter`, return tuple:(signalEsti,iter). \\n\n    If `conjGradIter` left default, -1, then it iterates enough times.\n    \"\"\"\n    n = Phi.shape[1] # signal length.\n    T0 = list(T0)\n    x0 = np.zeros(n)\n    # Init.\n    q = np.ones(n) # q=(q1,...,qn)\n    q[T0] = tau\n    # Q = np.diag(q)\n        # Inverse weight matrix. Not used so as to accelerate.\n    x0 = (q * Phi).T.dot(conjGrad(Phi.dot((q * Phi).T),y)) # Weight by row.\n        # Cost:O((m^2*n^2)^3)=poly(m,N).\n\n    for t in range(maxIter):\n        q = np.abs(x0)**(2-p)\n        q[T0] *= tau\n        q += mu\n        x1 = (q * Phi).T.dot(conjGrad(Phi.dot((q*Phi).T),y))\n        dx = x1 - x0\n        changeRate = np.sqrt(dx.dot(dx) / (x1.dot(x1) + eps**2)) \n        if showChangeRate:\n            print('Iter:',t,'ChangeRate:',changeRate) # Log.\n        if changeRate < np.sqrt(mu)/100:\n            if mu <= eps:\n                iter = t\n                break\n            else:\n                mu /= 10\n        x0 = x1\n    else: # Reach maxIter.\n        iter = maxIter-1\n        if showIfMaxIter:\n            print('Reach maxIter:',maxIter)\n    \n    if returnIter:\n        return (x1,iter)\n    else:\n        return x1","metadata":{"cell_id":"68b4d3d6b50e41898b38ee49873e726e","source_hash":"4a01e22d","execution_start":1680842284745,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# 3 动态CS算法\n## 3.1 LS-CS-residual","metadata":{"cell_id":"0a47ed4d5d504756a6fe2ed2f05817f2","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### 3.1.1 静态核 LS-CS-residual","metadata":{"cell_id":"d3b887392381445bb26d744f4011aa7e","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# LSCSresidualStatic\ndef LSCSresidualStatic(y:np.ndarray, Phi:np.ndarray, T0=[],\n            lamb=1e-1, alpha=0.05, alphaDel=0.15,\n            conjGradIter=-1,\n            returnIter=False,\n            showIfMaxIter=False, showChangeRate=False):\n    \"\"\"\n    Return (xEsti, T_Esti).\n    \"\"\"\n    m,n = Phi.shape\n    T0 = list(T0)\n    x0 = np.zeros(n) # x_init\n    x0[T0] = conjGrad(Phi[:,T0].T.dot(Phi[:,T0]),Phi[:,T0].T.dot(y))\n    yRes = y - Phi.dot(x0) # LS-residual y_res\n    # Variables for LP:\n    c = cvxopt.matrix(np.ones(2*n),(2*n,1),'d')\n    F = np.block([[Phi.T.dot(Phi),-Phi.T.dot(Phi)]])\n    dRes = Phi.T.dot(yRes)\n    G = np.block([[-np.identity(2*n)],\n                [F],\n                [-F]])\n    G = cvxopt.matrix(G,(4*n,2*n),'d')\n    h = np.block([np.zeros(2*n),\n                dRes + lamb*np.ones(n),\n                -dRes + lamb*np.ones(n)])\n    h = cvxopt.matrix(h,(4*n,1),'d')\n    xsol = cvxopt.solvers.lp(c,G,h)\n    xsol = np.array(xsol['x'])\n    xsol = xsol[:n]-xsol[n:] # Note! This solution is 2-d.\n    xsol = xsol[:,0]\n    x0 += xsol # x_CSres\n    # Detect:\n    Tdet = list(set(T0) | set(np.arange(n)[np.abs(x0)>alpha]))\n    x0 = np.zeros(n)\n    x0[Tdet] = conjGrad(Phi[:,Tdet].T.dot(Phi[:,Tdet]),Phi[:,Tdet].T.dot(y))\n        # x_det\n    # Delete:\n    Tt = list(set(Tdet) - set(np.arange(n)[np.abs(x0)<=alphaDel]))\n    x0 = np.zeros(n) # x_final\n    x0[Tt] = conjGrad(Phi[:,Tt].T.dot(Phi[:,Tt]),Phi[:,Tt].T.dot(y))\n\n    return (x0,Tt)","metadata":{"cell_id":"2abebe989ddc441185799dae88c33a07","source_hash":"bd9d2709","execution_start":1680842284746,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# -1 测试信号生成","metadata":{"cell_id":"17ed8c3639d948918ea0a2a416ebff7f","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# Rademacher(1,-1,Prob=0.5) on support.\ndef randSparseSignal(n=2000,s=50,size=10000,returnSupports=False,allowLowerSparsity=False):\n    \"\"\"\n    Generate `size` number of signals of dimension `n` and sparsity `s`.\n    Aranged by columns.\n\n    If `returnSupports`=`True` then also return Supports of Signals aranged by columns,\n    repetitions might be included.\n    \"\"\"\n    size = int(size) # 转化形如`1e5`的输入.\n    V =  np.zeros((n,size),order='F',dtype=np.float32)\n    Supps = np.array([np.random.choice(range(n),s,replace=allowLowerSparsity) for _ in range(size)])\n        # 随机抽取支集, 存为每一行.\n    Entries = np.array(\n        [np.random.binomial(1,0.5,s).astype(np.float32)*2-1 for _ in range(size)])\n        # 随机赋予支集项的值, 存为每一行.\n    for j in range(size):\n        V[Supps[j],j] = Entries[j]\n    if returnSupports==True:\n        return dict(\n            Signals = V,\n            Supports = Supps.T\n        )\n    else:\n        return V","metadata":{"cell_id":"389a485bc9d9496198030ea95de2f37e","source_hash":"c95d3f84","execution_start":1680842284747,"execution_millis":43,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# -2|Exec! 数值测试\n建议用直接代码写出, 不封装.","metadata":{"cell_id":"3ecbd6e174ff4a7098b0b778d486ae95","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# Generate A, X.\nnp.random.seed(42)\nA = randSampMat(200,500)\nXX = randSparseSignal(n=500,s=40,size=20,returnSupports=True)\nX, Supps = XX['Signals']*10,XX['Supports']\ndel XX","metadata":{"cell_id":"acb4955329f0451bb7c9b5bf3e435d6b","source_hash":"4e3fb9c2","execution_start":1680842307529,"execution_millis":8,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Mixed test. 需要的模拟次数可以远小于monteCarlo方法, 准确度也更大.\nRIPtest(A,40).mixedMethod(1000)","metadata":{"cell_id":"d51cc2a95b3d4a44bada51ae196e444f","source_hash":"9a11c6ec","execution_start":1680842312030,"execution_millis":342,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Max singular value: 1.4847175\nMin singular value: 0.5188008\n","output_type":"stream"},{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"0.4847174882888794"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"Y = np.dot(A,X[:,:10])","metadata":{"cell_id":"52adb01ecf0542e2ac826d69ca5bf816","source_hash":"d3db78aa","execution_start":1680842325463,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# IRLSPKS\nx = IRLSPKS(Y[:,0],A,showIfMaxIter=True,showChangeRate=True)\nerr = np.linalg.norm(x - X[:,0])\nprint(err)","metadata":{"cell_id":"3dcdb48677054412b3726cd15ea5fc90","source_hash":"6074544c","execution_start":1680842333870,"execution_millis":614,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Iter: 0 ChangeRate: 0.3326222304904642\nIter: 1 ChangeRate: 0.2076616661356135\nIter: 2 ChangeRate: 0.15832954706212196\nIter: 3 ChangeRate: 0.1261987030484299\nIter: 4 ChangeRate: 0.09574895100417553\nIter: 5 ChangeRate: 0.06891057582794216\nIter: 6 ChangeRate: 0.04778703077181044\nIter: 7 ChangeRate: 0.03235798797454024\nIter: 8 ChangeRate: 0.021576984685582553\nIter: 9 ChangeRate: 0.014250807750585329\nIter: 10 ChangeRate: 0.009358458973136833\nIter: 11 ChangeRate: 0.006126590985156321\nIter: 12 ChangeRate: 0.004005887479671831\nIter: 13 ChangeRate: 0.0026198090609430656\nIter: 14 ChangeRate: 0.0017156452677182768\nIter: 15 ChangeRate: 0.001126430072678166\nIter: 16 ChangeRate: 0.000742115751299719\nIter: 17 ChangeRate: 0.0004911463079153498\nIter: 18 ChangeRate: 0.00032686524194929916\nIter: 19 ChangeRate: 0.0002188121311282181\nIter: 20 ChangeRate: 0.0004083575390337776\nIter: 21 ChangeRate: 0.00025399934439571006\nIter: 22 ChangeRate: 0.00016165663115066947\nIter: 23 ChangeRate: 0.00010414754672424811\nIter: 24 ChangeRate: 6.782396034016356e-05\nIter: 25 ChangeRate: 7.201839245946232e-05\nIter: 26 ChangeRate: 4.5579161086424715e-05\nIter: 27 ChangeRate: 2.916095410585703e-05\nIter: 28 ChangeRate: 2.1855394849195823e-05\nIter: 29 ChangeRate: 1.3961488253892323e-05\nIter: 30 ChangeRate: 9.0008240421356e-06\nIter: 31 ChangeRate: 6.16539745870828e-06\nIter: 32 ChangeRate: 3.940678134556599e-06\nIter: 33 ChangeRate: 2.6169637896087265e-06\n0.00031048187314191276\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# RWLSSl0PKS\nx = RWLSSl0PKS(Y[:,0],A,showIfMaxIter=True,showChangeRate=True)\nerr = np.linalg.norm(x - X[:,0])\nprint(err)","metadata":{"cell_id":"26c4ce9e4df741c1af074590be6a27fc","source_hash":"6ebc106","execution_start":1680842342088,"execution_millis":94,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Iter: 0 ChangeRate: 0.4000220985499974\nIter: 1 ChangeRate: 0.32414734762070474\nIter: 2 ChangeRate: 0.28406632029154316\nIter: 3 ChangeRate: 0.08498648406179264\nIter: 4 ChangeRate: 0.0022462123355550347\nIter: 5 ChangeRate: 2.1985015149839753e-06\nIter: 6 ChangeRate: 1.0478832613145378e-10\n7.526331289471883e-05\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# CosampPKS\nErrCosampPKS = []\nfor j in range(Y.shape[1]):\n    x = CosampPKS(Y[:,j],A,50,maxIter=100,showIfMaxIter=True)\n    #看看误差.\n    err = np.linalg.norm(x - X[:,j])\n    ErrCosampPKS.append(err)\n    print(j,'Err:',err)\nelse:\n    print('Mean Err:',np.mean(ErrCosampPKS))\n\n# IHTPKS\nErrIHTPKS = []\nfor j in range(Y.shape[1]):\n    x = IHTPKS(Y[:,j],A,50,maxIter=100,showIfMaxIter=True)\n    #看看误差.\n    err = np.linalg.norm(x - X[:,j])\n    ErrIHTPKS.append(err)\n    print(j,'Err:',err)\nelse:\n    print('Mean Err:',np.mean(ErrIHTPKS))\n\n# OMPPKS\n# ErrOMPPKS = []\n# for j in range(Y.shape[1]):\n#     x = OMPPKS(Y[:,j],A,maxIter=100,showIfMaxIter=True)\n#     #看看误差.\n#     err = np.linalg.norm(x - X[:,j])\n#     ErrOMPPKS.append(err)\n#     print(j,'Err:',err)\n# else:\n#     print('Mean Err:',np.mean(ErrOMPPKS))\n\nplt.plot(ErrCosampPKS,ls='-.',label='cosamp')\nplt.axhline(np.mean(ErrCosampPKS),ls=':',label='mean cosamp')\nplt.plot(ErrIHTPKS,ls='--',label='iht')\nplt.axhline(np.mean(ErrIHTPKS),ls='-',label='mean iht')\n# plt.plot(ErrOMPPKS,label='omp')\nplt.legend()","metadata":{"cell_id":"18bbdc4507ef4942a50f82c58801a69a","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test 待改20230402\n# def test(Y,X,s,times=1000, func=IHTPKS, priorSuppRatio=0.2, SuppsReal=None, **kwargs):\n#     \"\"\"\n#     Run `times` times of `func` function\n#         given `Y`=[y1,...,yt], `X`=[x1,...,xt],\n#         use `priorSuppRatio`(from 0 to 1) instead of `T0`,\n#         `SuppsReal`: aranged by cols, if `None` then supps(X)(`s` needed),\n#         and `**kwargs` as other keyword arguments.\n    \n#     Return the results in an array.\n#     \"\"\"\n#     Results = []\n#     if SuppsReal is None:\n#         SuppsReal = np.zeros((s,X.shape[1])).astype('int')\n#         for j in range(X.shape[1]):\n#             SuppsReal[:,j] = np.argsort(np.abs(X[:,j]))[:-(s+1):-1] #兼容compressible signal.\n\n#     for t in range(times):\n#         T0 = np.random.choice(SuppsReal[:,t],int(round(s*priorSuppRatio,0)),replace=False)\n#         Results.append(func(y=Y[:,t],xReal=X[:,t],T0=T0,s=s,**kwargs))\n#     return Results","metadata":{"cell_id":"dff9c33f05fd4d75b1fb1e4252ed5d37","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# -99|Exec! Debug area","metadata":{"cell_id":"89647f443e8a432e91b64678e793a095","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"y = Y[:,0]\nn = 500\nPhi = A\nyRes = y\nlamb = 1e-5\nc = cvxopt.matrix(np.ones(2*n),(2*n,1),'d')\nF = np.block([[Phi.T.dot(Phi),-Phi.T.dot(Phi)]])\ndRes = Phi.T.dot(yRes)\nG = np.block([[-np.identity(2*n)],\n                [F],\n                [-F]])\nG = cvxopt.matrix(G,(4*n,2*n),'d')\nh = np.block([np.zeros(2*n),\n                dRes + lamb*np.ones(n),\n                -dRes + lamb*np.ones(n)])\nh = cvxopt.matrix(h,(4*n,1),'d')\nsol = cvxopt.solvers.lp(c,G,h)","metadata":{"cell_id":"9d8c18c1fad84ec9a56ef80f601ca630","source_hash":"f769f955","execution_start":1680842358291,"execution_millis":6601,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"     pcost       dcost       gap    pres   dres   k/t\n 0: -1.7764e-15 -1.0000e-02  1e+04  9e-01  1e+00  1e+00\n 1:  4.0626e+02  4.0698e+02  3e+03  3e-01  4e-01  1e+00\n 2:  4.2455e+02  4.2497e+02  1e+03  1e-01  2e-01  6e-01\n 3:  3.9781e+02  3.9801e+02  4e+02  5e-02  5e-02  3e-01\n 4:  4.0013e+02  4.0014e+02  1e+01  2e-03  2e-03  1e-02\n 5:  3.9999e+02  3.9999e+02  2e-01  2e-05  2e-05  1e-04\n 6:  3.9999e+02  3.9999e+02  2e-02  3e-06  3e-06  7e-06\n 7:  4.0000e+02  4.0000e+02  4e-03  8e-07  9e-07  2e-06\n 8:  4.0000e+02  4.0000e+02  1e-03  3e-07  3e-07  8e-07\n 9:  4.0000e+02  4.0000e+02  5e-04  1e-07  1e-07  3e-07\n10:  4.0000e+02  4.0000e+02  2e-04  5e-08  5e-08  1e-07\nOptimal solution found.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"x = np.array(sol['x'])\nx2 = x[:500]-x[500:]\nx2 = x2[:,0]","metadata":{"cell_id":"f195fd997c9e44f2bdca9addf85d1bc7","source_hash":"9291af5e","execution_start":1680842389028,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":26},{"cell_type":"code","source":"x1 = X[:,0]\nnp.linalg.norm(x1-x2)","metadata":{"cell_id":"05883132573e40d2b0ed2129d7261fe1","source_hash":"9ae6a242","execution_start":1680842391912,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"0.00018081681761364374"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"cell_id":"bc21466af39041379d07885551a314f9","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=988ed5b4-5ae4-41bf-a2ba-3058d1a94cd8' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"vscode":{"interpreter":{"hash":"0fa5ea0a09a8cd9d0aa4e6bbb526a74c2e7a420b3d09cd1311bf211743dd137b"}},"deepnote":{},"kernelspec":{"name":"python3","language":"python","display_name":"bachelorThesis"},"language_info":{"name":"python","version":"3.9.15","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"},"orig_nbformat":4,"deepnote_notebook_id":"942a2a8b145744c3aa69cf2126295b78","deepnote_execution_queue":[]}}